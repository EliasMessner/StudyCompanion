{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Integration Pipeline Demo\n",
    "# TODO Elias: prettify outputs and headlines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elias/miniconda3/envs/chatbot/lib/python3.10/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from pdf_and_text_utils import load_pdf, split_into_chunks\n",
    "from keyword_extraction_tfidf import get_search_terms, pdf_docs_to_str\n",
    "from scraper import load_web_content\n",
    "from vectorstore_controller import VectorstoreController"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:25:46.182524813Z",
     "start_time": "2023-06-03T10:25:40.951507858Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create vectorstoreController"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "vectorstore_controller = VectorstoreController()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:25:49.870541303Z",
     "start_time": "2023-06-03T10:25:46.186963794Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load pdf and add to vectorstore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pdf_path = \"spielwiese/test_pdf/3_RequirementsEngineering.pdf\"\n",
    "pdf_docs = load_pdf(pdf_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:25:56.711729767Z",
     "start_time": "2023-06-03T10:25:55.705541443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 342, which is longer than the specified 200\n",
      "Created a chunk of size 354, which is longer than the specified 200\n",
      "Created a chunk of size 488, which is longer than the specified 200\n",
      "Created a chunk of size 571, which is longer than the specified 200\n",
      "Created a chunk of size 256, which is longer than the specified 200\n",
      "Created a chunk of size 717, which is longer than the specified 200\n",
      "Created a chunk of size 285, which is longer than the specified 200\n",
      "Created a chunk of size 366, which is longer than the specified 200\n",
      "Created a chunk of size 351, which is longer than the specified 200\n",
      "Created a chunk of size 291, which is longer than the specified 200\n",
      "Created a chunk of size 254, which is longer than the specified 200\n",
      "Created a chunk of size 241, which is longer than the specified 200\n",
      "Created a chunk of size 225, which is longer than the specified 200\n",
      "Created a chunk of size 419, which is longer than the specified 200\n",
      "Created a chunk of size 572, which is longer than the specified 200\n",
      "Created a chunk of size 882, which is longer than the specified 200\n",
      "Created a chunk of size 227, which is longer than the specified 200\n",
      "Created a chunk of size 324, which is longer than the specified 200\n",
      "Created a chunk of size 213, which is longer than the specified 200\n",
      "Created a chunk of size 224, which is longer than the specified 200\n",
      "Created a chunk of size 437, which is longer than the specified 200\n",
      "Created a chunk of size 215, which is longer than the specified 200\n",
      "Created a chunk of size 294, which is longer than the specified 200\n",
      "Created a chunk of size 220, which is longer than the specified 200\n",
      "Created a chunk of size 313, which is longer than the specified 200\n",
      "Created a chunk of size 204, which is longer than the specified 200\n",
      "Created a chunk of size 276, which is longer than the specified 200\n",
      "Created a chunk of size 534, which is longer than the specified 200\n",
      "Created a chunk of size 219, which is longer than the specified 200\n",
      "Created a chunk of size 296, which is longer than the specified 200\n",
      "Created a chunk of size 203, which is longer than the specified 200\n"
     ]
    },
    {
     "data": {
      "text/plain": "Upserted vectors:   0%|          | 0/137 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3fd22baf8db4a2fa2ed253d90c0d29a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "['30cef338-ca88-4917-ade5-abadcbb36a04',\n 'c3e57413-ad24-4829-9ea0-2a8859dbc7af',\n '8b4080f9-2e26-43a9-b519-b35bdd185848',\n 'a209e61f-e3cf-40a8-bde3-ccd0b39ca1ed',\n '92057f3f-369d-4914-b893-8a2226757888',\n '7b079cff-c809-48de-b636-de751ae07950',\n '0127e840-eb3c-4297-a1c1-79f2d1088124',\n 'e03d4955-037c-40dd-8bf5-881e399556a5',\n '1a51b10a-470c-4ed6-92c5-bb0a3839274f',\n '072e7470-4ef0-446b-bd6c-5e17b52d98bd',\n '9ad4b9d2-2088-4730-bec2-395524212851',\n 'b282cf73-3013-45a3-b279-d3888cfa4591',\n '2dced0e1-d986-4503-a3de-778d90664c6f',\n '9d39af14-4bf1-4390-840f-d08563efe271',\n 'e5907e77-03a3-4ce2-9670-e8d29a67f155',\n '9dabbb31-aa4d-43d5-b6e4-f3c8f8ac0348',\n 'fadce74d-0020-40dc-afec-f726921f3957',\n '6c3d4f36-db7e-4a04-a4c8-296cf5eb42c5',\n '329e13d2-f68e-4aeb-a400-b6ce07b3f938',\n '36b53f70-d115-417c-b289-b7ad85c100a8',\n 'd53a7912-1a59-4bab-84e7-4e24b0d9dc1c',\n '05bf3a32-6ada-4490-8179-734861578919',\n '53bb2c2f-d0cb-418e-81fe-c079585ab183',\n '3ee96157-d1fc-426d-80bb-291267410c98',\n '38ad1ba3-304d-4054-a670-84a8a4ad954f',\n 'a2657954-67b0-4144-a6c2-3891093540ea',\n '34a209e2-ccc1-46d3-be65-164fbfc694df',\n 'de1df98b-0550-435b-9b22-00af98229426',\n '487bb17d-dd55-4b52-a5db-965028f06607',\n '3b495c91-cad4-4730-92ae-f8293edebcd9',\n '5be75f7a-4d40-40a0-82f6-b93a70afbf23',\n '36f4be05-4100-489c-b330-2f2daad54233',\n 'd2f74e57-ab70-453c-9e7f-3c58c7a97383',\n '7090d4b1-2e6f-4363-924a-f0e7ea3fd56f',\n '9537f882-d007-43eb-b04c-b300ff868f8f',\n '1488da8b-712e-44a0-be7d-49e19a8a029f',\n 'acbce7fd-9a97-4c93-8c5b-16517b95c903',\n 'b297f59b-f201-495b-905d-50482f1e6e17',\n '301d0f8d-c55e-4eab-840f-75c777157d90',\n 'cfb9c151-dd64-4eda-8cbd-dea45821d287',\n 'e8b1c9fc-ffbd-46d1-9777-98c4899315e2',\n '83f3c311-460a-4964-ac1d-5aaed728c577',\n 'c9afedf3-b726-4b3f-9cd5-440bca025e3e',\n '3a91409b-b66d-4037-b398-ac95052134cb',\n '10b01451-32c4-4165-984b-2c7886adb8eb',\n 'dd3823fc-57ee-446f-90e1-4dd7fb832086',\n '90391fac-d950-4b81-be96-c4a281b5113c',\n 'c30c305f-966a-4184-adbc-05af94baccf3',\n 'f61b839b-ddd9-41b5-8efa-4b91ea802c59',\n '852d332d-ea20-4210-8676-9a32f93ba8d1',\n '03c388a1-0f14-4abe-a4aa-c4532e656a3f',\n 'b00d8a01-07cc-4d3e-83c2-243457eac212',\n 'd4728689-7fcb-47bf-98d8-e617b2eb530a',\n '1adc5221-cde0-40b5-aafa-388990f61630',\n 'a648798a-bc20-4b58-9f5d-d74dd31ffcef',\n '023674b6-d928-4a67-b7c4-068383e5a35f',\n 'd3112f44-0318-4f53-ab3e-00a87eb9ca75',\n '6d2ee664-e54d-4e08-9593-17fd3db2c6cf',\n '2360ef2a-7494-4196-b707-8b8088c7335b',\n '675a2aac-8fc6-49a8-9ab6-62456ffa2829',\n '1bc351d5-0c4e-4a2a-af85-12d244449957',\n '1659e2af-32f9-4ed3-941a-dd31931bce36',\n '9e47d79f-eff0-46e3-83e0-039e50bba405',\n 'e9b50a9a-5c35-4342-9c14-d569e6ec90e7',\n 'd32ede63-a622-49d0-8d44-2571f849c864',\n 'fd17775a-0ebf-45f4-9290-e885dbe380a0',\n 'ca708cc8-2cdd-4d56-9398-deeb43d826a5',\n '40fc6588-35c7-461f-beb6-54432140a0c4',\n '1a19948f-87e7-4e44-9356-c6ce7c236ade',\n 'd7996fe4-bf4e-4e99-9450-d0242ea63c13',\n '78f99a38-a9fc-40b2-b9d3-f8af8f648844',\n '98ed598b-5605-4f12-b333-c52dd88dc4ec',\n '05bb479a-ae5e-4763-a5c9-56879f8942cb',\n '50e9f767-c00c-4c5a-a1c6-6b29ea3342ff',\n 'd4e296c5-4298-4b0f-a876-48c4ff01c59d',\n '54fefbe7-8a2e-426d-9cf6-b6d435e606c5',\n '8b8fe86f-68c9-402a-924a-2051039e76eb',\n '68c413b3-5d2d-4208-8d28-ace3e9ae98be',\n '88fedee0-2926-4325-ba29-30ce6c4b027d',\n 'c5055286-8509-40f1-ab6d-e83d7520dcf9',\n '6bdf0b1c-01f3-460f-8b2b-f24231ce2a85',\n 'a8dd868d-381a-4884-bf70-f80c6a106c73',\n 'ab1a8ad3-8d95-4af0-b7b7-e37b015316d2',\n 'c08497f6-a166-4f8f-b0ad-61c661f81183',\n '529c6f3e-2099-40f2-aae7-45d9c2b91379',\n '8c0a26af-f453-4ffe-bac4-7e2bd060bf9f',\n '308c767a-bf45-46ea-83a7-52bce749b1dd',\n '959c9d5d-91a7-4cc3-bb77-b05c18998ce4',\n '20e3a678-a43b-40f9-96ef-4c884bb3b252',\n '90bd9da1-0632-4187-a8d3-115753355baf',\n '351cf8c9-115d-4881-a7ca-72ad8da32c09',\n 'a7eac30c-129e-46c1-a9c0-448d4e121445',\n '28eb7b2b-d360-4e51-b86f-f4299e203ba9',\n 'c6cefc74-a17c-4f4c-9dc3-63da1ae4c75a',\n '1853abf3-771b-4e64-842e-bd26522b94cb',\n '472ee03b-8bce-4d48-b38b-121bd93ac551',\n '3681ab1a-ef8d-4a74-972f-2d45cf95cea7',\n 'bab35d1e-909a-433e-981e-7bf677951b2c',\n '7566ee67-a1be-4073-a443-3cc530c95d34',\n 'ec9ea9b6-59f9-42ec-9d57-f0ff263494b0',\n '7f89d335-b05c-442e-8ae7-129e9a66eb5a',\n '762b083f-503c-4fb3-847a-186c4df0602b',\n 'd1ed835c-aa0f-4eee-8353-144dd688527b',\n '0ff08409-9163-4df3-bb91-31274b5ec9b5',\n '57cc040a-a6a1-4294-9a50-ca9ea45f147a',\n '63b03ee4-e8aa-4572-b378-b22180c5d89e',\n 'c47d47d2-5992-4556-9d0e-ab6633cbfb25',\n '8c25e1ca-d41d-4072-a6bb-d651606b68c0',\n 'f0ffc5c6-af83-42b8-9eff-6a9003e83d6d',\n 'f53b42b1-564f-4137-898d-745d75748823',\n '21a04d9d-5217-4eef-96af-2bdb83e18985',\n '0cd76fd3-5fbf-4176-ab68-ee535a4b06bc',\n 'b0d3b6d1-f265-4f17-acd0-790c99dc49e5',\n '9c65c1df-6559-44f4-9abe-1de30894adbb',\n '38ae63c0-66ab-4340-a987-9819f85cc265',\n '77584d86-bd7c-4874-af48-5366b047fa2c',\n 'fa50ec61-3923-4c0d-b777-1c09e16a210a',\n '3a5e7a81-f024-4084-adb0-933df5bd4fe7',\n '83058f96-e8b3-4b19-96b9-25e847093d47',\n 'baa8a7d8-edc2-4e5e-8187-6db0ffcea644',\n '705f891b-6e9e-4ece-a9c4-139c44f380fd',\n '0cf46982-8d57-4f6b-8345-ae75aa00581c',\n '49c2d78e-235f-42bb-af30-9621bb67c763',\n '205675a3-0c6e-4e4e-b9ce-288ff5e3fff6',\n '9f7e7908-de76-4d9c-ab6b-510ec63a6efc',\n '6adc4730-1040-433a-90be-0b785705c3e5',\n 'f5748fe5-2cfa-4ee4-9335-222b24a54d5e',\n 'd93aea7b-9635-4322-b576-2b95abfe5cd8',\n '317de8dc-6b65-445e-a93a-92e024a10f9f',\n 'c33e7c8c-b5bb-43e8-97ba-3b87bfb7b444',\n '9663e57b-78a3-453a-a61b-8fb5ce9fa16b',\n '84495001-3383-4636-a93e-4a9167a0449b',\n '66a57d0f-7f26-48ee-9fc0-11f29a13c30e',\n '2ce77094-635c-4552-885e-becda959b29d',\n 'cc685e5a-ad7f-460c-bac8-b273c5d0951f',\n '5e8c5604-df2e-493a-928c-8398380fe615',\n '4d730227-bdb0-41ea-9880-c0bb448acfa5']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = split_into_chunks(pdf_docs)\n",
    "vectorstore_controller.add_documents_to_vectorstore(splits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:20:27.786878227Z",
     "start_time": "2023-06-03T10:20:19.015276648Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Extract search query from pdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'data model requirements specification non functional ai component research attempts'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_str = pdf_docs_to_str(pdf_docs)\n",
    "search_query = get_search_terms(text=pdf_str)\n",
    "search_query"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:25:59.439409902Z",
     "start_time": "2023-06-03T10:25:59.094887550Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Scrape the web for content and store in vectorstore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------\n",
      "Scraping: https://medium.com/@purvanshimehta/coding-interview-resources-ml-data-science-ai-research-engineer-b7cc2fbf81ab?source=search_post---------7----------------------------\n",
      "Scraping: https://medium.com/analytics-vidhya/nonlinear-regression-tutorial-with-radial-basis-functions-cdb7650104e7?source=search_post---------5----------------------------\n",
      "Scraping: https://medium.com/neuri-ai/wattnet-learning-to-trade-fx-with-hierarchical-spatio-temporal-representations-of-highly-bbd0f02c812f?source=search_post---------1----------------------------\n",
      "Scraping: https://medium.com/@dassanawijesekara/non-performance-requirements-of-consumer-data-standards-specification-open-banking-in-australia-f947ee013578?source=search_post---------0----------------------------\n",
      "Scraping: https://medium.com/towards-data-science/why-robustness-is-not-enough-for-safety-and-security-in-machine-learning-1a35f6706601?source=search_post---------2----------------------------\n",
      "Scraping: https://medium.com/@purvanshimehta/interview-resources-ml-data-science-ai-research-engineer-4703518d208e?source=search_post---------6----------------------------\n",
      "Scraping: https://medium.com/real-ventures/canadas-artificial-intelligence-ecosystem-4798b0517016?source=search_post---------3----------------------------\n",
      "Scraping: https://medium.com/towards-artificial-intelligence/openai-brings-introspection-to-reinforcement-learning-agents-39cbe4cf2af3?source=search_post---------4----------------------------\n"
     ]
    }
   ],
   "source": [
    "web_content = load_web_content('chrome', search_query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:26:36.847788194Z",
     "start_time": "2023-06-03T10:26:04.600009788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonlinear Regression Tutorial with Radial Basis Functions\n",
      "\n",
      "Joseph Gatto·Follow\n",
      "\n",
      "Published inAnalytics Vidhya·4 min read·Mar 23, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Let's take a look at basis function regression which allows us to model non-linear relationships. If you are familiar with regular linear regression, then you know the goal is to find parameters (α,β) such that we can find the line of best fit y=αx+β.\n",
      "\n",
      "When performing non-linear regression, we are no longer just solving for an equation of a line. Now, our high-level goal is to solve for the best linear combination of a set of basis functions that allows us to model something non-linear.\n",
      "\n",
      "In other words, imagine we have some simple dataset\n",
      "\n",
      "Now, suppose we have a set of basis functions that can be anything we want! For RBF regression, we are going to use a collection of Gaussians like this.\n",
      "\n",
      "For RBF-based regression, we transform the input with the following kernel\n",
      "\n",
      "Where cₖ is the center/mean of gaussian k and σ is the standard deviation of said gaussian. Each of these are hyperparameters of our model. More specifically, the hyperparameters include 1) how many basis functions 2) where each one is located and 3) The variance of each Gaussian. In my example below, I choose the center of each gaussian such that they are evenly spaced along our training data and arbitrarily chose a standard deviation of 1. There may be smarter ways to choose these parameters for other types of problems.\n",
      "\n",
      "To summarize, what we want is to solve for the optimal weights w, so we can best solve y=b(x)ᵗw. We can solve for these parameters the same way we do in regular linear regression. Recall that for linear regression, this means solving for parameters w requires we do the following:\n",
      "\n",
      "We can do the same for non-linear regression. Namely,\n",
      "\n",
      "What we are left with is a weight vector with k weights, one for each of our radial basis functions. As we will see, we can then transform any input x into an output y’ as a linear combination of our basis functions.\n",
      "\n",
      "Let's take a look at some results using different numbers of basis functions when trying to fit a non-linear RGB regressor to a sin curve\n",
      "\n",
      "As we can see, when we use too few basis functions we are unable to capture the nature of the sin curve. However, for too large a number of basis functions, we severely overfit the data.\n",
      "\n",
      "Sources:\n",
      "\n",
      "http://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/NonlinearRegression.pdf\n",
      "###################\n",
      "Canada’s Artificial Intelligence Ecosystem — Montreal\n",
      "\n",
      "Part 1: Montreal’s non-predatory model — how fellowship has fostered the world’s strongest AI research community\n",
      "\n",
      "Real Ventures·Follow\n",
      "\n",
      "Published inReal Ventures·8 min read·Apr 20, 2018\n",
      "\n",
      "ListenShare\n",
      "\n",
      "2\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Written by Laura Easton, edited by Lauren Jane Heller\n",
      "\n",
      "This is the first of a series of posts aimed to provide an insider perspective on all aspects of Canada’s AI ecosystem, with a particular focus on Montreal and Toronto — two of Canada’s most active AI cities.\n",
      "\n",
      "Johnny Chen on\n",
      "\n",
      "Unsplash\n",
      "\n",
      "There’s no question that Canadian AI is booming. But what makes the Canadian major cities such exceptional hubs of research and startup activity?\n",
      "\n",
      "After digging into the history of key AI actors and institutes in Montreal, the relationships among them and their impact on local entrepreneurs and the growth of the community, we found that Montreal’s AI story has three parts, all of which have positive network effects for startups and corporations working in AI:\n",
      "\n",
      "Research roots and a collaborative model\n",
      "\n",
      "An AI research network that has drawn global interest and talent\n",
      "\n",
      "Local and global supporters\n",
      "\n",
      "Montreal’s non-predatory model\n",
      "\n",
      "The major difference between Montreal and many other technology hubs is the atmosphere of fellowship and the belief that scientific progress should be for everyone. This foundation of knowledge sharing — forged by some of the most prominent AI researchers in the world — has led to to a convergence of AI talent and research support, as well as the establishment of AI research labs, both academic and corporate, in the city.\n",
      "\n",
      "Montreal is rooted in its research\n",
      "\n",
      "La Belle Ville has research roots that extend across the globe. Many top AI researchers have engaged with academic programs in the city and some, including Hugo Larochelle of Google Brain, have left and then returned to Montreal to grow privately-funded AI labs. With corporations anxiously recruiting the less than 22,000 people in the world who have the skill-set to tackle tough AI problems—often through astronomic salaries —there is now an even greater need for top researchers to train next generation talent.\n",
      "\n",
      "This is Montreal’s strength, thanks to a conglomerate of great minds brought together by Yoshua Bengio. Professor Bengio is a Canadian computer scientist, AI pioneer, and part of the “Deep Learning Conspiracy.” Decades ago, when deep learning theories about neural network operations failed to meet practical applications, financial support froze and the research fell into an AI winter. While most researchers waited for computing power and data to ramp-up, computer scientists, Geoffrey Hinton, Yann LeCun and Yoshua Bengio, kept the fire going. As data became the new currency and AI scaled, Hinton and LeCun were recruited to work with Google and Facebook, respectively.\n",
      "\n",
      "Yoshua Bengio, however, remained committed to academia and the training of the next generation of senior experts in deep learning. The non-predatory model his team created at the Montreal’s Institute for Learning Algorithms (MILA) and more recently through the co-founding of Element AI, is keeping major research talent in universities rather than siloed in big corporations, all the while facilitating the commercialization of AI knowledge via collaboration with startups and enterprises. Bengio’s dedication to research through his investment in developing programs at Université de Montréal, MILA, through Element AI, and other research institutes, has also shone a bright light on Montreal’s AI Ecosystem and led to a significant number of prominent tech companies establishing their AI presence in Montreal.\n",
      "\n",
      "Montreal’s magnetic AI research network\n",
      "\n",
      "While Bengio may be Montreal’s AI pioneer, it’s the research institutes and critical mass of AI intelligence workers that have drawn in the interest of corporations and startups looking to harness this cutting-edge technology.\n",
      "\n",
      "In 2016, machine learning researchers, largely from Université de Montréal and McGill University, established Montreal’s Institute for Learning Algorithms (MILA), an institute that facilitates and democratizes access to talent and research for applied AI in the business sector. MILA attracts top post-doctoral and PhD talent from all over the world and is building the next generation of AI researchers. Organizations can gain access to technical and business advisory services related to R&D — including those provided by MILA — through the Canadian National Research Council’s Industrial Research Assistant Program (IRAP), which is committed to helping Canadian firms build competitive advantages.\n",
      "\n",
      "MILA’s expertise and programs are complemented by other publicly and privately-funded institutes:\n",
      "\n",
      "The Computer Research Institute of Montreal (CRIM) has served Quebec enterprises by acting as a bridge between university research and business needs since 1985 and has collaborated on AI projects for nearly 30 years. Researchers at CRIM execute projects similar to MILA but on a smaller scale. Entrepreneurs and enterprises can access CRIM resources through a membership model, which opens up a large network of IT companies, as well as subject-matter expertise and innovation partnerships.\n",
      "\n",
      "IVADO, Montreal’s Institute for Data Valorization, fills the supply/demand gap faced by CRIM and MILA by democratizing and raising awareness of machine learning and operations knowledge through membership programs. Since 2015, this partnership between Université de Montréal, HEC Montréal and Polytechnique Montréal has curated an innovation network of more than seventy partners including major Montreal players in transportation, energy, commerce and healthcare. As members of IVADO, entrepreneurs and enterprises join a platform for knowledge exchange and collaboration between the specialists, partners, researchers and students in its network.\n",
      "\n",
      "In the past two years, there has also been a major influx of privately-funded AI research labs to Montreal, driven by the convergence of talent and proximity to key resources for information exchange and collaboration. This concentration of expertise helps reinforce developments in AI applications and grow new AI-focused businesses.\n",
      "\n",
      "Among the most notable are:\n",
      "\n",
      "Element AI, co-founded in 2016 by Jean-Francois Gagne and Yoshua Bengio. The team has quickly grown to 300 employees over the past two years and is the largest privately-owned Canadian AI R&D lab.\n",
      "\n",
      "Microsoft acquired Montreal AI lab, Maluuba, in early 2017 with plans to double technical experts to 75 over the next two years.\n",
      "\n",
      "Samsung Electronics’ Advanced Institute of Technology (SAIT) opened an AI lab in the Université de Montréal in August 2017. SAIT has been collaborating with Bengio and other partners from the University of Toronto, McGill University and NYU since 2014.\n",
      "\n",
      "Google Brain recruited former student of Bengio and Montreal native, Hugo Larochelle, in mid-2017, to run their AI research in Montreal.\n",
      "\n",
      "Facebook established FAIR Montreal in late 2017 and hired Joelle Pineau (a McGill University Professor of Computer Science) to head this lab. FAIR is hiring 10 researchers initially and plans to triple in size by the end of 2018.\n",
      "\n",
      "DeepMind, acquired by Google in 2014, announced the opening of a research lab in Oct 2017 headed by Doina Precup (McGill University Professor of Computer Science).\n",
      "\n",
      "Thales SA, announced plans to open a lab in Montreal in October 2017. They are currently members of IVADO and plan to partner with MILA. By mid-2019, they hope to expand to 50 AI scientists.\n",
      "\n",
      "The Royal Bank of Canada will open a Borealis AI lab in 2018. They aim to have ten researchers on staff in the first year.\n",
      "\n",
      "These corporations were drawn to Montreal by the expertise of the city’s researchers, yet many of the labs are being led by academics like Bengio, Precup and Pineau, who will continue to teach at their respective universities, while overseeing the application of their research for business purposes. Further, because of the prominence of these researchers — and importance of their labs’ developments — there has been a major injection of financial support into university research centres by both government and multinational players.\n",
      "\n",
      "Major support for a flourishing AI ecosystem\n",
      "\n",
      "The Canadian and Quebec governments, as well as international corporations, are playing a crucial role in both funding Montreal research organizations and in the recruitment and retention of talent in Canada. There is no question that global AI leadership is a national priority. In the past two years, Quebec has received significant funding that has enabled the province to reinforce and build infrastructure to better serve local AI initiatives and attract and retain AI researchers, entrepreneurs and research labs.\n",
      "\n",
      "This support comes from two major sources: government (federal, provincial and municipal) and multinational (corporate and philanthropic) funds.\n",
      "\n",
      "Government support:\n",
      "\n",
      "In September 2016, the Canada First Research Excellence Fund allocated:\n",
      "\n",
      "$84 million to McGill University for their Healthy Brains for Healthy Lives (HBHL) initiative\n",
      "\n",
      "$93.5 million to Université de Montréal for Optimization of Deep Learning and Knowledge sharing (IVADO)\n",
      "\n",
      "In March 2017, $40 million was allocated to Montreal from the Government of Canada’s $125M Pan-Canadian AI Strategy, administered by the Canadian Institute for Advanced Research (CIFAR).\n",
      "\n",
      "In spring 2017, $100 million was allocated by the Government of Quebec for the creation of a provincial wide cluster and institute for Artificial Intelligence.\n",
      "\n",
      "In March 2018, the Government of Quebec communicated the grant of:\n",
      "\n",
      "$5 million toward the establishment of an international organization on artificial intelligence\n",
      "\n",
      "$10 million toward NEXT.AI and CDL, initiatives of HEC Montreal, over the next five years\n",
      "\n",
      "Corporate and Multinational funds:\n",
      "\n",
      "In 2016, Google announced it would give $3.33 million USD over three years to the MILA\n",
      "\n",
      "In early 2017: Microsoft contributed $7 million USD to McGill University and Université de Montréal AI Labs\n",
      "\n",
      "In August 2017: MILA was awarded $2.4 million USD research grant from the US-based Open Philanthropy Project, to make AI safer for society\n",
      "\n",
      "As this financial support has rolled in, the City of Montreal is working hard to build infrastructure to serve local AI startups and research labs, with Montreal International, the city’s economic development agency for foreign investment leading efforts to attract more AI talent and corporate investment, and Montreal’s Chambre de Commerce (CCMM) driving thought leadership and local engagement via Quebec’s biggest AI forum of the year.\n",
      "\n",
      "Montreal’s critical mass in AI: a win for the ecosystem\n",
      "\n",
      "The investment into AI research and infrastructure is fuelling the AI fire in Montreal. For major corporations, this means access to a much larger pool of talent and the latest cutting edge research. For startups building AI-first companies, the cost of living and quality of life in Montreal means that more researchers will be interested in joining teams that can’t pay astronomical salaries (yet!), and they can also benefit from the latest cutting-edge research through MILA, IVADO and the other institutes.\n",
      "\n",
      "As Montreal’s talent attracts international attention and investment in Montreal labs, more AI talent is drawn to the city and facilitates knowledge sharing of AI developments. This positive feedback loop of talent attracting talent and developments driving knowledge sharing, has and will continue to drive growth in Montreal’s thriving AI ecosystem.\n",
      "\n",
      "All of this together paints a clear picture: Montreal is a city to watch, or move to, for those interested or working in cutting-edge artificial intelligence. The open nature and organic fellowship that defines Montreal’s entrepreneurial communities are proof that the city’s non-predatorial model works. The AI community goes further together, rather than faster alone.\n",
      "\n",
      "2018 Snapshot\n",
      "\n",
      "Techstars.AI and NEXT AI Accelerators. As content develops in this series, this map will become more granular, highlighting relationships and linking to definitions and resources as appropriate.\n",
      "\n",
      "In next posts in this series, we will dive into the Toronto AI ecosystem and then zoom out to look at the broader Canadian AI landscape, what startups are doing and how Canada’s major AI hubs compare internationally.\n",
      "\n",
      "Follow us for these and other in-depth articles!\n",
      "###################\n",
      "Coding Interview types: ML/Data Science/AI Research Engineer\n",
      "\n",
      "Curated list of types of questions to prepare for\n",
      "\n",
      "Purvanshi Mehta·Follow\n",
      "\n",
      "3 min read·Apr 12, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "2\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "I recently interviewed with Microsoft (Data Scientist ll), Amazon (Applied AI Scientist) and Apple (Software Development : Machine Learning). I wrote about the preparation involved on the Machine Learning side and received a lot of questions about coding questions in interviews.\n",
      "\n",
      "These are the major types of questions I was asked. Obviously the difficulty will varying according to the team and the company. Feel free to add more questions!\n",
      "\n",
      "Take home assignments\n",
      "\n",
      "These are my favorite types of tests because you can actually showcase your skills. Here are some of the types of questions I have been asked\n",
      "\n",
      "A dataset will be given and you will need to build Machine Learning models to show how much your model perform on the test data in 24 hours as compared to others. The task usually relates to the your everyday job in the company.\n",
      "\n",
      "Basics of probability and statistics questions- I got one question which involved finding some bounds on a custom algorithm and then proving it theoretically. There can be questions for hypothesis testing and interpreting the results.\n",
      "\n",
      "Some pointers you can keep in mind for acing such interviews -\n",
      "\n",
      "Put in good documentation for your code\n",
      "\n",
      "Show your Object Oriented programming skills even if you are coding in jupyter notebook and python. Eg. You can have a different visualization module.\n",
      "\n",
      "Have a through Data Analysis part- This shows that you have tried to understand the problem statement. It’s a plus if you include some hypothesis tests in your analysis.\n",
      "\n",
      "Standard Data Structure and Algorithms questions\n",
      "\n",
      "These are leetcode type questions. Usually these are not very tough if your team is a bit research oriented or more Machine Learning focused. In fact going through some algorithm and data structure basics should be enough. Be sure you can code a basic problem in 20–30 minutes.\n",
      "\n",
      "Live coding\n",
      "\n",
      "Different companies have different types of live coding sessions and sometimes there can be multiple people evaluating you at the same time. These can also be of three types\n",
      "\n",
      "DS / Algo questions- One thing to practice in this part is that you are able to code the basic structure in a few minutes so that you can concentrate on the problem solving more. Eg. Given a graph question be sure to code the main graph class quickly along with some traversal if required.\n",
      "\n",
      "Deep Learning coding- I have been asked to code simple image classification, sequence to sequence model. The interviewer is not checking your syntax but the flow. Example you should know how to form a custom dataloader, why you zero the gradients before backpropagating and the type of loss you will use… and so on.\n",
      "\n",
      "Machine learning algorithms coding- I was asked to code random forest followed by bagging and boosting (not kidding here!). I realized the interviewer was only trying to check if I understand the differences and have a direction of how will it be implemented.\n",
      "###################\n",
      "Interview resources : ML/Data Science/AI Research Engineer\n",
      "\n",
      "A curated list of topics, resources and questions\n",
      "\n",
      "Purvanshi Mehta·Follow\n",
      "\n",
      "3 min read·Feb 15, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "8\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Interviewing is a grueling process, specially during COVID. I recently interviewed with Microsoft (Data Scientist ll), Amazon (Applied AI Scientist) and Apple (Software Development : Machine Learning).\n",
      "\n",
      "Though all these interviews differed a bit, but the basic questions asked were the same. During the process I curated this list which would help you pass all ML interviews.\n",
      "\n",
      "NOTE : This list is just for end moment revising\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Linear, Logistic regression-http://cs229.stanford.edu/notes2020spring/cs229-notes1.pdf\n",
      "\n",
      "Naive Bayes- https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c\n",
      "\n",
      "SVM / Kernel- http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes3.pdf\n",
      "\n",
      "Random Forests, decision Trees, Boosting, Bagging, Xgboost- StatQuest Youtube videos https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\n",
      "\n",
      "EM Algorithm- http://cs229.stanford.edu/notes2020spring/cs229-notes8.pdf\n",
      "\n",
      "K means-https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n",
      "\n",
      "K nearest neighbors- https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n",
      "\n",
      "Evaluation Metrics (scroll to the definition section, you need to know the confusion metrics, precision, recall, type I, type II, FP rate, sensitivity)-https://en.wikipedia.org/wiki/Precision_and_recall\n",
      "\n",
      "Regularization (L1,L2, Why is L1 sparse?) https://explained.ai/regularization/L1vsL2.html\n",
      "\n",
      "Bias Variance Trade off\n",
      "\n",
      "Dimensionality Reduction-\n",
      "\n",
      "PCA deeplearning book chapter 2 (last pages) https://www.deeplearningbook.org/contents/linear_algebra.html\n",
      "\n",
      "TSNE https://distill.pub/2016/misread-tsne/\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "The first thing I would suggest to do is to go through all the deeplearnig.ai courses which is pretty basic. If someone already publishes/ works in these topics they might just skip watching all the videos and can go through the following questions/ resources-\n",
      "\n",
      "Know what is- K fold cross validation, dropout, batch norm [Difference between batch norm and layer norm], early stopping\n",
      "\n",
      "Weight decay https://www.coursera.org/lecture/deep-neural-network/regularization-Srsrc\n",
      "\n",
      "Calibration https://arxiv.org/abs/1706.04599 (Look to what is calibration and ECE score)\n",
      "\n",
      "Transformer- The Illustrated Transformer — Jay Alammar — Visualizing machine learning one concept at a time. (jalammar.github.io)\n",
      "\n",
      "Attention (Multi head, single head) Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) — Jay Alammar — Visualizing machine learning one concept at a time. (jalammar.github.io)\n",
      "\n",
      "Different Optimizers (Important are- Gradient descent, Adam, RMSprop, Adagrad, Adamax)- An overview of gradient descent optimization algorithms (ruder.io)\n",
      "\n",
      "Initialization- Initializing neural networks — deeplearning.ai\n",
      "\n",
      "NLP\n",
      "\n",
      "For NLP CS224 (5) Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 1 — Introduction and Word Vectors — YouTube) covers the basics of NLP with Deep Learning. This might cover 3/4 of the questions asked in an interview. Other questions are usually more state of the art models as the interviewer wants to check how updated you are.\n",
      "\n",
      "LSTM, GRU- Understanding LSTM Networks — colah’s blog\n",
      "\n",
      "BERT- A Visual Guide to Using BERT for the First Time — Jay Alammar — Visualizing machine learning one concept at a time. (jalammar.github.io) , GPT- GPT models explained. Open AI’s GPT-1,GPT-2,GPT-3 | Walmart Global Tech Blog (medium.com) and you can read the respective papers\n",
      "\n",
      "Different types of embeddings (Bag of words, TFIDF, Word2vec(skipgram[How is it trained], pre-trained (Google word2vec, Stanford Glove, fasttext, ELMo))). Need to know how incremental changes were brought into place.\n",
      "\n",
      "Other topics —\n",
      "\n",
      "Linear Algebra-https://www.deeplearningbook.org/contents/linear_algebra.html\n",
      "\n",
      "Probability basics- http://www2.ece.rochester.edu/~gmateosb/ECE440/Slides/block_2_probability_review_part_a.pdf\n",
      "\n",
      "Stats- I had taken a graduate level Statistics class so I didnt need to brush this up but Khan Academy https://www.khanacademy.org/math/statistics-probability is a very good source for learning basics with examples.\n",
      "\n",
      "These are the topics which are asked in all interviews, obvious then some questions were specific to research I had done. There were also live coding rounds both of algorithms and NN models. Let me know if I missed something.\n",
      "###################\n",
      "AI Alignment and Safety\n",
      "\n",
      "Why Robustness is not Enough for Safety and Security in Machine Learning\n",
      "\n",
      "Christian Kästner·Follow\n",
      "\n",
      "Published inTowards Data Science·14 min read·Jan 6, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Researchers in multiple communities (machine learning, formal methods, programming languages, security, software engineering) have embraced research on model robustness, typically cast as safety or security verification. They make continuous and impressive progress toward better, more scalable, or more accurate techniques to assess robustness and prove theorems, but the many papers I have read in the field essentially never talk about how this would be used to actually make a system safer. I argue that this is an example of the streetlight effect: We focus research on robustness verification, because it has well-defined measures to evaluate papers,whereas actual safety and security questions are much harder and require to consider the entire system, not just properties of the model. When thinking of testing, safety and security of production machine learning systems, we need to step beyond narrow measures of robustness.\n",
      "\n",
      "From Adversarial Examples to Robustness\n",
      "\n",
      "We have probably all seen examples of how easily machine learning models can be fooled into making wrong predictions by adding slight noise to the input that may be imperceptible to humans, such as this panda recognized (with high confidence) as a gibbon when some minor noise that’s pretty much invisible to humans is added:\n",
      "\n",
      "OpenAI\n",
      "\n",
      "In a nutshell, the problem occurs, because we learn and use models without understanding how they work internally and whether they actually learn concepts that would mirror human cognition. The models tend to work on average (as our accuracy measures indicate during model evaluation), but we often really do not know why and how — and maybe we don’t care as long as they mostly work. However, since we don’t know and cannot specify how these models work, we can always find examples of wrong predictions, where the model simply does not produce the expected result. Worse, with suitable search, it is often possible to find small variations of a specific input that change the model’s prediction. This is known as adversarial examples, and there is a huge amount of research on how to find them, with and without access to the model’s internals.\n",
      "\n",
      "While the panda-gibbon example might look fun, it is easy to reframe adversarial examples as safety and security problems. For examples, researchers have shown that small stickers taped to a stop sign can fool a vision system to recognize the sign as a “Speed Limit 45” sign, implying that this might lead to wrong and dangerous actions taken by an autonomous car:\n",
      "\n",
      "CVPR 2018 paper\n",
      "\n",
      "Beyond intentional attacks by manipulating inputs, also natural changes to inputs may lead to wrong predictions with safety consequences. The most common examples are self-driving cars driving in foggy weather conditions or with a slightly titled or smeared camera, all resulting in small modifications of the input. For example, researchers have shown how simple transformations of the image (mirroring possible real-world problems) can lead to wrong predictions of the car’s steering angle:\n",
      "\n",
      "DeepTest ICSE 2018 paper\n",
      "\n",
      "In this context, robustness is the idea that a model’s prediction is stable to small variations in the input, hopefully because it’s prediction is based on reliable abstractions of the real task that mirror how a human would perform the task. That is, small invisible noise should not flip the prediction from panda to gibbon, small additions to the image should not prevent the model from recognizing a stop sign, and weather conditions or slightly titling the camera should not affect the steering angle of a self-driving car.\n",
      "\n",
      "Making machine learning robust against adversarial inputs.\n",
      "\n",
      "Side note: I like Goodfellow et al.’s visual explanation of adversarial examples as a mismatch between the actual decision boundary (ground truth/specification) and the model’s learned decision boundary. Unfortunately, we use machine learning exactly because we don’t have a clear specification and don’t know the actual decision boundary (see my discussion of specifications in Machine Learning is Requirements Engineering). Hence the explanation is a nice conceptual view, but not very helpful in a practical setting, where we care about whether a prediction is correct. Robustness relates only to the question whether we are near the model’s decision boundary, without knowing anything about the actual decision boundary.\n",
      "\n",
      "Defining Robustness\n",
      "\n",
      "Robustness is an appealing property to study, because it is easy to define well as an invariant over the relation of two inputs (technically a metamorphic relation) without having to rely on specifications and ground truth of what the actual correct prediction is.\n",
      "\n",
      "The way the distance is defined may differ a lot based on the problem. Typical examples allow for low amounts of noise to all input features (e.g., all pixels), arbitrary changes to few input features (e.g., change any three pixels), or more complicated transformations (e.g., tilting the picture or adding “fog”). Whatever the possible transformations or corresponding distance functions and maximum distance, we always reason about some neighborhood around the original input.\n",
      "\n",
      "Note that this definition does not require any information about what the correct prediction for f(x) or f(x’) is, we simply reason about the fact that the prediction shall stay consistent (whether correct or not) within a neighborhood.\n",
      "\n",
      "Robustness is either established as a binary property, i.e., an input for a model is verified as robust or not (usually conservative overapproximations, but also probabilistic judgments with a confidence level have been proposed), or as some form of relative measure, e.g., the distance to the nearest adversarial example or the percentage of robust inputs in the neighborhood.\n",
      "\n",
      "Researchers now developed many different search and verification strategies to evaluate this robustness property for deep neural networks. This can be done by searching for adversarial examples within the neighborhood, by simply sampling and testing a large number of data points in the neighborhood, or by different forms of formal verification that formally prove that no point in the neighborhood can change the prediction result.\n",
      "\n",
      "Notice that robustness research focuses essentially exclusively on deep neural networks, because this is where it is hard to scale proof techniques. In contrast, I’m not aware of robustness papers on decision tress or linear models and it seems that robustness evaluations would be fairly straightforward to implement and fairly scalable for many such models — I suspect that’s why I haven’t seen such papers.\n",
      "\n",
      "In addition to local robustness, some researchers have also discussed a global robustness property of a model, typically some form of average robustness for all possible inputs. For example, one could measure for what percent of inputs robustness can be verified or what the average distance is from each input to the nearest adversarial example.\n",
      "\n",
      "Side note: As studied by Borg et al.: Robustness is a term that practitioners use a lot, but usually just vaguely referring to correctness or trustworthiness of the model’s predictions, not the formal notion of robustness studied in the research literature and discussed here.\n",
      "\n",
      "Is Robustness Useful?\n",
      "\n",
      "I have read dozens of papers analyzing robustness of machine-learned models and most of them motivate the analysis with safety and security concerns — yet none of those papers discussed or even evaluate how robustness would be really used in a practical setting.\n",
      "\n",
      "First of all, robustness is difficult to interpret. The only model that is fully robust for all inputs is the trivial model that returns the same prediction for all outputs. For all other models, there is a decision boundary and some inputs will be close to the model’s decision boundary and hence not robust: some parts of the neighborhood of inputs near the decision boundary will be on each side of the decision boundary.\n",
      "\n",
      "Use case 1: Evaluating robustness at inference time\n",
      "\n",
      "The most plausible usage scenario seems to be to evaluate robustness at inference time, that is, check whether a given prediction made by a system during its operation is robust. For example, when labeling images, we could only label those images for which we have proof or confidence that the label is robust to minor perturbations (independent of the confidence score the model may already provide) and thus decide not abstain from labeling the panda in the image above. Similarly, we could identify that the stop sign is not robustly identified as a stop sign and thus not trust it as any sign for decisions made by the self-driving car.\n",
      "\n",
      "This seems appealing and robustness can be a powerful tool, but to actually use it for safety and security of systems, engineers need to solve multiple additional problems:\n",
      "\n",
      "Costly analysis: State of the art robustness analysis for deep neural networks is very costly. Even though techniques get better, they currently scale only to small and mid-sized neural networks (handwritten digit recognition anyone?) and they typically take minutes to analyze robustness of a single input, due to the cost of the formal analysis, the SMT solving, or the huge number of samples needed. We can certainly hope for research progress to continue to reduce the cost, but it’s hard for me to imagine anybody to use robustness evaluations any time soon at inference time; not for high-volume systems like tagging photos at Facebook and certainly not for real-time applications as self-driving cars.\n",
      "\n",
      "Defining maximal distance: Defining a suitable distance function and threshold for the size and shape of the neighborhood is a nontrivial engineering problem. The larger the neighborhood, the more predictions will be classified as not robust. If the neighborhood is too small, attacks and accidental misclassifications are more likely to slip through. Also what perturbations are plausible to occur in practice due to accidents or attacks and how to define the right neighborhood? What are the worst cases we want to protect against? Identifying the right distance function and maximum distance threshold are nontrivial engineering challenges.\n",
      "\n",
      "Robust≠safe: If we analyze robustness at inference time and we have found a reasonable maximal distance, what do we do with model predictions that determined as being not robust? We could simply decide not to label the image, but we cannot just stop steering the self-driving car. Also, are we assuming that a prediction will be correct, just because it is robust? We clearly need to think about safety mechanisms beyond the model, still anticipating that the model may make wrong predictions or simply indicate more often that it is not sure.\n",
      "\n",
      "Notice that the cost argument may not apply to simpler ML models such as decision trees, though I have not seen anybody discuss using robustness at inference time for those either. I would really be interested in seeing projects that try to design safe systems and discussions how they address these challenges.\n",
      "\n",
      "Use case 2: Global model assessment\n",
      "\n",
      "It is possible to evaluate the average robustness of a model for arbitrary inputs, measured as some global robustness property. We might consider this as an additional measure of model quality, in addition to prediction accuracy (ROC, recall/precision, lift, MAPE, whatever), where robustness and accuracy measure very different qualities. Note that the evaluation can be done entirely offline; cost may be high, but this strategy does not slow down model inference in production.\n",
      "\n",
      "A model that is on average more robust may be preferable, because it may be assumed to learn more actual concepts, be restricted to fewer simpler decision boundaries, or may be affected less by noise or attacks.\n",
      "\n",
      "Challenges now come from how to measure and meaningfully interpret global robustness. Do we really care about all inputs equally, or shall robustness focus on more common inputs? For example, many approaches have been used to generate synthetic “test” inputs that are not robust, but do we really care about random inputs that do not resemble any real-world inputs? Also similar to accuracy measures, what level of robustness is considered good? What neighborhood size should be used? How would we make tradeoffs between accuracy and robustness? Overall, global model robustness is easy to define as a metric, but it is unclear how to make use of that metric.\n",
      "\n",
      "And finally, say we have established high average robustness, how does this help us make any safety or security claims? We hope that the model makes fewer mistakes or is harder to attack, but we do not know anything about a specific prediction at inference time. In a practical setting, an attacker may very well be able to find adversarial examples for many actual inputs.\n",
      "\n",
      "Use case 3: Debugging the model\n",
      "\n",
      "Instead of evaluating robustness globally (use case 2), we can evaluate robustness of a set of actual inputs. For example, we could evaluate the robustness of every single input in the validation data set (hopefully representative of actual inputs in production) or even in the training set. We could also analyze robustness of a sample of inputs received in the production system, say, random inputs or inputs flagged as problematic through the system’s telemetry (e.g., users reported predictions as incorrect).\n",
      "\n",
      "Knowing whether certain predictions on sample inputs are robust may help us with debugging. We might identify areas of inputs for which many predictions are not robust — either because they are truly close to the real decision boundary or, more likely, because the model is simply not very good at understanding these inputs. We might identify dangerous conditions, such as the inability of our model to deal with fog — hopefully identified during testing not in production.\n",
      "\n",
      "If we understand problems of the model, we may then try to improve the model. The most common strategy seems to be data augmentation, where inputs from the neighborhood of training inputs are added to the training data. Changes to the model architecture or feature engineering may also help to nudge the model to learn more relevant concepts. Many many papers explore different approaches here.\n",
      "\n",
      "Overall, this seems a promising strategy to debug, harden, and generally improve models. A key challenge is the question of which inputs should be used for robustness analysis (leading to hard questions about curating a good test set) and, as above, how to define the maximum distance to consider. Also similar to use case 2, we won’t have any robustness guarantees about how the model behaves in production. None of this improves a system’s safety or security by itself.\n",
      "\n",
      "Going beyond the model: Safety is a system property\n",
      "\n",
      "Safety and security are system properties, not properties of software or machine-learned models. As safety research Nancy Leveson (MIT) puts (repeatedly) it in her ICSE’20 keynote talk:\n",
      "\n",
      "“Software is not unsafe. It can contribute to a hazard, but it does not explode, catch on fire, involve toxic materials, etc. If it is not about hazards, it is not about safety. […] Software is not unsafe; the control signals it generates can be. […] It is not possible to look at software alone and determine safety […] Virtually all software-related accidents have resulted from unsafe requirements, not software design/implementation errors.”\n",
      "\n",
      "Safety is all about building safe systems, often from unreliable components, including software and hardware components. It is about making sure that the system overall is safe, even if a component fails (e.g., hardware failure, a model makes a wrong prediction) or unanticipated interactions arise among multiple components.\n",
      "\n",
      "Given that we cannot specify the expected behavior of a machine-learned model and cannot verify it’s functional correctness, the safety question must concern how the system interacts with the environment based on outputs from machine-learned models that are often unreliable. We must think about safeguards outside the model, such as a thermal fuse or maximal toasting duration in a smart toaster that ensures that the toaster does not catch fire no matter what it’s internal model predicts as toasting times.\n",
      "\n",
      "Engineering safe systems requires understanding requirements at the system level, analyzing the interactions between the world and the machine, as well as understanding the interactions of various (possibly unreliable) components. It is the context of how the model is used that determines whether the model is safe.\n",
      "\n",
      "Model robustness does ensures neither safety nor security itself. Robustness ensures nothing about “correctness” of a model: robust predictions can still be wrong; a very robust model can be completely useless. Robustness may be a useful building block in a larger safety story (with all the open engineering challenges discussed above), since it changes assumptions we can make about an ML component when we consider interactions with other parts of the system and the environment. But only making a model robust does not make the system safe.\n",
      "\n",
      "There is research work on building safe systems with machine-learned models, especially around avionics and self-driving cars—it’s all about requirements and system design and system-level testing, whereas assuring a formal robustness property usually does not seem to be much of a concerns there.\n",
      "\n",
      "Aleksandar Pasaric)\n",
      "\n",
      "So back to the streetlight effect, (named after the story of a man searching his wallet under a streetlight and when asked “Is this where you lost your wallet” replies that he lost it elsewhere, but it’s easier to search here where the light is): Robustness of deep neural networks is a thankful research topic because it is well defined, challenging, with room for clearly measurable improvements over the state of the art. Many researchers have made incredible contributions. However, if we are really concerned about safety and security of production systems with machine-learning components, we should look beyond the simple and well-defined problems at the real and ugly engineering challenges of real-world systems.\n",
      "\n",
      "Further readings:\n",
      "\n",
      "My prior posts on quality assurance of ML-enabled systems: Machine Learning is Requirements Engineering (on the notion of correctness and the role of specifications), A Software Testing View on Machine Learning Model Quality (on testing strategies beyond accuracy), The World and the Machine and Responsible Machine Learning (on system-level thinking and requirements engineering)\n",
      "\n",
      "Paper surveying safety engineering for ML systems in current automotive engineering: Borg, Markus, Cristofer Englund, Krzysztof Wnuk, Boris Duran, Christoffer Levandowski, Shenjian Gao, Yanwen Tan, Henrik Kaijser, Henrik Lönn, and Jonas Törnqvist. “Safely entering the deep: A review of verification and validation for machine learning and a challenge elicitation in the automotive industry.” Journal of Automotive Software Engineering. Volume 1, Issue 1, Pages 1–19. 2019\n",
      "\n",
      "Paper on safety engineering and architectural safety patterns for autonomous vehicles: Salay, Rick, and Krzysztof Czarnecki. “Using machine learning safely in automotive software: An assessment and adaption of software process requirements in ISO 26262.” arXiv preprint arXiv:1808.01614 (2018).\n",
      "\n",
      "Another paper discussing different safety strategies for autonomous vehicles: Mohseni, Sina, Mandar Pitale, Vasu Singh, and Zhangyang Wang. “Practical Solutions for Machine Learning Safety in Autonomous Vehicles.” SafeAI workshop at AAAI’20, (2020).\n",
      "\n",
      "Survey paper listing many recent robustness verification techniques (in Sec 4): Huang, Xiaowei, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu, and Xinping Yi. “A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability.” Computer Science Review 37 (2020).\n",
      "\n",
      "Annotated bibliography on software engineering for AI-enabled systems including several papers on robustness, security, and safety\n",
      "###################\n",
      "Member-only story\n",
      "\n",
      "Top 10 Architecture Characteristics / Non-Functional Requirements with Cheatsheet\n",
      "\n",
      "Love Sharma·Follow\n",
      "\n",
      "Published inDev Genius·7 min read·Jun 30, 2022\n",
      "\n",
      "ListenShare\n",
      "\n",
      "14\n",
      "\n",
      "-\n",
      "\n",
      "14\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Imagine you are buying a car. What essential features do you need in it? A vehicle should deliver a person from point A to point B. But what we also check in it is Safety, Comfort, Maintainability, Ease of repair or Better mileage. You may also look for an electric version or better speed. Why? To limit the surprises which may occur in delivering the primary function, i.e., take a person from Point A to Point B.\n",
      "\n",
      "Similarly, just like a car, motorcycle, or House, the software has its non-functional requirements called “Architectural Characteristics”. Be it a website, a mobile or a desktop app; it should have a set of quality attributes to meet end-user needs.\n",
      "\n",
      "Architecture Characteristics / Non-Functional Requirements\n",
      "\n",
      "Briefly, functional requirements define what a system is supposed to do, like in the case of a car, take a person from A to B, and non-functional requirements stipulate how a system is supposed to be.\n",
      "\n",
      "Here is the overall cheatsheet of NFR:\n",
      "\n",
      "https://imgur.com/a/HzPp8s0\n",
      "\n",
      "These top 10 Architectural Characteristics covers most of the aspect of a large-scale project. You don’t need to accommodate all in your project; pick the most essential and knock it out. This article is not providing the solution to these NFRs but instead makes you aware of which areas you need to consider when designing a system.Let’s understand each one of them:\n",
      "\n",
      "Scalability:\n",
      "\n",
      "The ability for the system to perform and operate as the number of users or requests increases. Scalability is achievable with Horizontal or vertical scaling of the machine or simply attaching AutoScalingGroup.\n",
      "\n",
      "Traffic Pattern: Understand the traffic pattern of the system. It’s not cost-efficient to spawn as many machines as possible, even if it is underutilisation.\n",
      "\n",
      "Diurnal Pattern: Traffic increases in the morning and decreases in the evening for a particular region.\n",
      "\n",
      "Global / Regional: Regional Heavy usage of the application.\n",
      "\n",
      "Thundering Herd: Many users are requesting resources, but only a few machines are available to serve the burst of traffic. These could occur during peak time or in densely populated areas.\n",
      "\n",
      "Elasticity: Ability to quickly spawn a few machines to handle the burst of traffic and gracefully shrink when the demand is reducing.\n",
      "\n",
      "Latency: Ability to serve the request as quickly as possible. This also includes optimising the algorithms and replicating the system near users to reduce the round trip of a request. An average google search takes 400 ms.\n",
      "\n",
      "Availability\n",
      "\n",
      "It is measured as a percentage of uptime and defines the proportion of time that a system is functional and working. Availability is affected by system errors, infrastructure problems, malicious attacks and system load.\n",
      "\n",
      "Deployment Stamps: Deploy multiple independent copies of application components, including data stores\n",
      "\n",
      "Geodes: Deploy backend services into a set of geographical nodes, each of which can service any client request in any region.\n",
      "\n",
      "Extensibility\n",
      "\n",
      "Extensibility measures the ability to extend a system and the effort required to implement the extension. The extension can be through adding new functionality or modifying existing functionality. The principle provides for enhancements without impairing current system functions.\n",
      "\n",
      "Modular / Reusability: Reusability, together with extensibility, allows technology to be transferred to another project with less development and maintenance time, as well as enhanced reliability and consistency.\n",
      "\n",
      "Pluggability: Ability to easily plug other components like in the case of microkernel architecture.\n",
      "\n",
      "Consistency\n",
      "\n",
      "Consistency guarantees that every read returns the most recent write. This means that after the execution of every operation, the data is consistent across all the nodes, and thus all clients see the same data at the same time, no matter which node they connect to. Consistency improves the data freshness.\n",
      "\n",
      "Resiliency\n",
      "\n",
      "A system can gracefully handle and recover from accidental and malicious failures. Detecting failures and recovering quickly and efficiently is necessary to maintain resiliency.\n",
      "\n",
      "Recoverability: The preparatory processes and functionality enable you to return your services to an initial functioning state after an unintended change. Unintended changes include the soft or hard deletion or misconfiguration of applications.\n",
      "\n",
      "Disaster Recovery: Disaster recovery (DR) consists of best practices designed to prevent or minimise data loss and business disruption resulting from catastrophic events — everything from equipment failures and localised power outages to cyberattacks, civil emergencies, criminal or military attacks, and natural disasters.\n",
      "\n",
      "Design Patterns:\n",
      "\n",
      "Bulkhead: Isolate elements of an application into pools so that if one fails, the others will continue to function.\n",
      "\n",
      "Circuit Breaker: Handle faults that might take a variable amount of time to fix when connecting to a remote service or resource.\n",
      "\n",
      "Leader Election: Coordinate the actions performed by a collection of collaborating task instances in a distributed application by electing one instance as the leader that assumes responsibility for managing the other instances.\n",
      "\n",
      "Usability\n",
      "\n",
      "Usability can be described as the capacity of a system to provide a condition for its users to perform the tasks safely, effectively, and efficiently while enjoying the experience. It is the degree to which specified consumers can use software to achieve quantified objectives with effectiveness, efficiency and satisfaction in a quantified context of use.\n",
      "\n",
      "Accessibility: Make the software available to people with the broadest range of characteristics and capabilities. This includes users with deaf, blind, colourblindness, etc.\n",
      "\n",
      "Learnability: How easy users can learn how to use the software?\n",
      "\n",
      "API Contract: For Internal teams, understanding the API Contracts can help easily pluggable into any system.\n",
      "\n",
      "Observability\n",
      "\n",
      "Observability is the ability to collect data about program execution, internal states of modules, and communication between components. To improve observability, use various logging and tracing techniques and tools.\n",
      "\n",
      "Logging: There are different types of logs generated within each request: event logs, transaction logs, message logs and server logs.\n",
      "\n",
      "Alerts & Monitoring: Prepare monitoring dashboards, create SLI (Service Level Indicators) and set up critical alerts.\n",
      "\n",
      "L1 / L2 / L3: Setup on-call support process for L1 / L2. L1 support includes interacting with customers. L2 support manages the tickets routed to them by L1 and helps troubleshoot. L3 is the last line of support and usually comprises a development team which addresses the technical issues.\n",
      "\n",
      "Security\n",
      "\n",
      "Degree the software protects information and data so that people or other products or systems have the degree of data access appropriate to their types and levels of authorisation. This family of characteristics includes confidentiality (data is accessible only to those authorised to have access), integrity (the software prevents unauthorised access to or modification of software or information), nonrepudiation (can actions or events be proven to have taken place), accountability (can user actions of a user be traced), and authenticity (verifying the identity of a user).\n",
      "\n",
      "Auditability: Audit trails track system activity so that when a security breach occurs, the mechanism and extent of the breach can be determined. Storing audit trails remotely, where they can only be appended, can keep intruders from covering their tracks.\n",
      "\n",
      "Legality:\n",
      "\n",
      "Compliance: Adhere to data protection laws like GDPR, CCPA, SOC2, PIPL or FedRamp.\n",
      "\n",
      "Privacy: Ability to hide transactions from internal company employees (encrypted transactions so even DBAs and network architects cannot see them).\n",
      "\n",
      "Authentication: Security requirements to ensure users are who they say they are.\n",
      "\n",
      "Authorisation: Security requirements to ensure users can access only certain functions within the application (by use case, subsystem, webpage, business rule, field level, etc.).\n",
      "\n",
      "Durability\n",
      "\n",
      "Durability is the solution ability of software’s serviceability and meet users’ needs for a relatively long time.\n",
      "\n",
      "Replication: involves sharing information to ensure consistency between redundant resources to improve reliability, fault-tolerance, or accessibility.\n",
      "\n",
      "Fault Tolerance: It is the property that enables a system to continue operating correctly in the event of the failure of one or more faults within some of its components.\n",
      "\n",
      "Archivability: Will the data need to be archived or deleted after some time? (For example, customer accounts will be deleted after three months or marked as obsolete and archived in a secondary database for future access.)\n",
      "\n",
      "Agility\n",
      "\n",
      "It has become today’s buzzword when describing a contemporary software method. An associate agile team could be a handy team able to befitting reply to changes. Modification is what software development is highly abundant.\n",
      "\n",
      "Maintainability: How easy it is to apply changes and enhance the system? — Represents the degree of effectiveness and efficiency to which developers can modify the software to improve it, correct it, or adapt it to changes in environment and requirements.\n",
      "\n",
      "Testability: how easily developers and others can test the software\n",
      "\n",
      "Ease of development: the degree to which developers can modify the software without introducing defects or degrading existing product quality\n",
      "\n",
      "Deployability: The time to get code into production after committing the deployment time.\n",
      "\n",
      "Installability: Ease of system installation on all necessary platforms.\n",
      "\n",
      "Upgradeability: Ability to easily/quickly upgrade from a previous version of this application/solution to a newer version on servers and clients.\n",
      "\n",
      "Portability: Does the system need to run on more than one platform? (For example, does the frontend need to run against Oracle and SAP DB?\n",
      "\n",
      "Configurability: The end users can easily change aspects of the software’s configuration (through usable interfaces).\n",
      "\n",
      "Compatibility: Degree to which a product, system, or component can exchange information with other products, designs, or members and perform its required functions while sharing the same hardware or software environment.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Now, that you are familiar with the NFRs or Architectural Characteristics, you may be thinking that which one will fit your project needs. Or may be all of them are required in every project. So how to proceed with adopting these characteristics within your project?\n",
      "\n",
      "Once you get the functional requirement, try to find the bottleneck in the system which may add obstacle to primary function. And how to find the bottleneck? Try answering few of such questions:\n",
      "\n",
      "Will the system perform in 100M / 1B userbase?\n",
      "\n",
      "Will my system handles 10,000 concurrent request?\n",
      "\n",
      "Am I handling the data in secured way?\n",
      "\n",
      "Can I add more features easily without impacting the existing working features?\n",
      "\n",
      "and many more…\n",
      "\n",
      "Some of these questions can help to identify the bottleneck or less performing area which are potential start point to improve the overall reliability of the system.\n",
      "\n",
      "Did I missed anything? If yes, Please help to enrich this article by sharing your thoughts in comments.\n",
      "\n",
      "With that, I conclude this learning; I hope you have learned something new today. Please do share with more colleagues or friends. Finally, Consider becoming a Medium member. Thank you!\n",
      "###################\n",
      "Member-only story\n",
      "\n",
      "Artificial Intelligence\n",
      "\n",
      "OpenAI Brings Introspection to Reinforcement Learning Agents\n",
      "\n",
      "The research around Evolved Policy Gradients attempts to recreate introspection in reinforcement learning models.\n",
      "\n",
      "Jesus Rodriguez·Follow\n",
      "\n",
      "Published inTowards AI·4 min read·Apr 12, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "https://janzz.technology/the-rise-of-the-machines-cognitive-computing-disruptive-potential/\n",
      "\n",
      "I recently started an AI-focused educational newsletter, that already has over 80,000 subscribers. TheSequence is a no-BS (meaning no hype, no news etc) ML-oriented newsletter that takes 5 minutes to read. The goal is to keep you up to date with machine learning projects, research papers and concepts. Please give it a try by subscribing below:\n",
      "\n",
      "TheSequenceSubscribe to stay up-to-date with the most relevant projects and research papers in the AI world. Trusted by 85,000+…thesequence.substack.com\n",
      "\n",
      "Introspection is one of those magical cognitive abilities that differentiate humans from other species. Conceptually, introspection can be defined as the ability to examine conscious thoughts and feelings. Introspection also plays a pivotal role in how humans learn. Have you ever tried to self-learn a new skill such as learning a new language? Even without any external feedback, you can quickly assess whether you are making progress on aspects such as vocabulary or pronunciation. Wouldn’t it be great if we could apply some of the principles of introspection to artificial intelligence(AI) discplines such as reinforcement learning (RL)?\n",
      "\n",
      "The magic of introspection comes from the fact that humans have access to very well shaped internal reward functions, derived from prior experience on other tasks, and through the course of biological evolution. That model highly contrasts with RL agents that are fundamentally coded to start from scratch on any learning task relying mainly on external feedback. Not surprisingly, most RL models take substantially more time than humans to learn similar tasks. Recently, researchers from OpenAI published a new paper that proposes a method to address this challenge by creating RL models that know what it means to make progress on a new task, by having experienced making progress on similar tasks in the past.\n",
      "\n",
      "Titled Evolved Policy Gradients(EPG), the OpenAI research paper introduces new meta-learning technique based on the concept of a loss function that qualifies the learning progress. When used in RL models, the EPG method does not encode the knowledge explicitly through memorized behaviors but, instead, it uses an implicitly mechanism through a learned loss function. The EPG end goal is that RL agents that can use this loss function to learn a novel task.\n",
      "\n",
      "Algorithmically, EPG consists of two optimization loops. In the inner loop, an agent learns, from scratch, to solve a particular task sampled from a family of tasks. The family of tasks might be “move gripper to target location [x, y]” and one particular task in this family could be “move gripper to position [50, 100]“. The inner loop uses stochastic gradient descent (SGD) to optimize the agent’s policy against a loss function proposed by the outer loop. The outer loop evaluates the returns achieved after inner-loop learning and adjusts the parameters of the loss function, using Evolution Strategies (ES), to propose a new loss that will lead to higher returns.\n",
      "\n",
      "From the metalearning standpoint, the loss function consists of temporal convolutions over the agent’s recent history which can lead to interesting side benefits. For instance, by examining the agent’s history, the loss could incentivize desirable extended behaviors, such as exploration. Further, the loss could perform a form of system identification, inferring environment parameters and adapting how it guides the agent as a function of these parameters (e.g., by adjusting the effective learning rate of the agent).\n",
      "\n",
      "Metalearning policies is nothing new in the RL field but the EPG techniques does bring some very tangible benefits compared to traditional approaches. One of the most obvious advantages of the EPG method is that it avoids the local-minima Achilles’ heel of RL models. Since RL methods optimize for short-term returns instead of accounting for the complete learning process, they may get stuck in local minima and fail to explore the full search space. The EPG method allows RL models to optimize for the true objective, namely the final trained policy performance, rather than short-term returns. In initial tests, EPG seems to improves on standard RL algorithms by allowing the loss function to be adaptive to the environment and agent history, leading to faster learning and the potential for learning without external rewards.\n",
      "\n",
      "Among the interesting tests conducted by the OpenAI researchers in order to test the generalization ability of EPG, there was an experiment focused on using the EPG loss to be effective at getting “ants” to walk to randomly located targets on the right half of an arena. After an initial calculation of the loss function, the experiment gave the ants a new target, this time on the left half of the arena. Surprisingly, the ants learned to walk to the left! Here is how their learning curves looked (red lines on graph.\n",
      "\n",
      "The type of knowledge generalization achieved by EPG models is very encouraging compared to traditional metalearning models because is doesn’t rely on the training distribution. The OpenAI team complemented the research paper with an initial implementation of EPG available on Github. The EPG implementation is based on the Python and Anaconda which should make it relatively simple to use with other deep learning frameworks.\n",
      "###################\n",
      "WATTNet: Learning to Trade FX with Hierarchical Spatio-Temporal Representations of Highly Multivariate Time Series\n",
      "\n",
      "Neuri Research·Follow\n",
      "\n",
      "Published inneuri-ai·13 min read·Sep 12, 2019\n",
      "\n",
      "ListenShare\n",
      "\n",
      "1\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Financial data is notoriously difficult to model due to non-stationarity, noise and complexity of the underlying dynamics. What is often available are merely extremely noisy and incomplete observations of an inaccessible state space; in general, the more sources of data that can be leveraged, the easier it can be to recover the true state of the system, and the longer it can take (computationally).\n",
      "\n",
      "This is the big challenge of time series, in particular the highly multivariate kind. Edward Lorenz, MIT mathematician, meteorologist and one of the fathers of the theory of chaos, is known to have concluded “long-term weather forecasting is doomed” after noticing that simulation data across experiments starting at near-identical conditions diverged completely. Recent results have confirmed Lorenz’s estimate: weather forecasting seems to be fundamentally intractable beyond a time horizon of two weeks. Financial dynamics are very much similar to weather dynamics: a multitude of highly non-linear factors interact non-linearly to determine future trajectories. Chaotic sensitivity to the slightest perturbations and stochastic terms reliant on unpredictable human behavior corrupt and warp the data and add another layer of complexity to the already challenging problem of predicting the future.\n",
      "\n",
      "It is therefore natural to conclude that models capable of capturing inter and intra-dependencies in highly multivariate time series are fundamental in finance. Many, if not most, of such interaction terms are nonlinear and thus challenging to analyze with standard statistical approaches. As Campbell et al. [1] argue:\n",
      "\n",
      "...many aspects of economic behavior may not be linear. Experimental evidence and casual introspection suggest that investors' attitudes towards risk and expected return are nonlinear. The terms of many financial contracts such as options and other derivative securities are nonlinear. And the strategic interactions among market participants, the process by which information is incorporated into security prices, and the dynamics of economy-wide fluctuations are all inherently nonlinear. Therefore, a natural frontier for financial econometrics is the modeling of nonlinear phenomena.This is quite a challenge, since the collection of nonlinear models is much 'larger' than the collection of linear models—after all, everything which is not linear is nonlinear. Moreover, nonlinear models are generally more difficult to analyze than linear ones, rarely producing closed-form expressions which can be easily manipulated and empirically implemented. In some cases, the only mode of analysis is computational, and this is unfamiliar territory to those of us who are accustomed to thinking analytically, intuitively, and linearly.\n",
      "\n",
      "A direct consequence has been the new-found popularity of data-driven models for financial forecasting tasks, in particular recurrent neural networks (RNN) and their variants. Recurrent models, while offering an intuitive approach to time series modeling, lack an explicit module to capture inter-dependencies and perform relational reasoning [2]. Different approaches to time series modeling rely on temporal convolutions (TCN) as their fundamental computational block. Particularly successful in this area of research is WaveNet [3], originally developed as a generative model for speech data. However, vanilla WaveNet and its derivative models are primarily designed to handle univariate time series and are thus ill-suited for highly multivariate financial time series.\n",
      "\n",
      "In this post, we will present an alternative to WaveNet specifically designed for the multivariate case. WaveATTentionNet (WATTNet) incorporates computationally efficient dilated convolutions for temporal learning of autoregressive effects and self-attention modules to learn spatial, inter-time series interaction terms. Here is an overview of a WATTNet applied to an M-dimensional multivariate time series {X}:\n",
      "\n",
      "We will present the details in the following sections. In particular, we’ll elaborate on the two fundamental components of WATTNet: temporal learning modules, based on dilated convolutions, and spatial modules, based on self-attention. For more updates check our github repository; we will release complete code at a later date.\n",
      "\n",
      "Temporal learning: dilated convolutions\n",
      "\n",
      "Dilated convolutions are essentially convolutions at lower resolutions. They offer improved computational efficiency and a method to avoid overfitting potentially noisy high-frequency components at the cost of a loss of information.\n",
      "\n",
      "WaveNet notoriously introduced dilated convolutions in the temporal, 1-dimensional case. The dilation coefficient is doubled each layer as an efficient way to extend the temporal receptive field of the model:\n",
      "\n",
      "WATTNet follows the same trend and utilizes temporal dilated convolutions to learn autoregressive terms for each of the input time series. Each univariate time series has access to its own set of convolutional weights as temporal convolution operations are carried on independently:\n",
      "\n",
      "Independence between convolutions is necessary to provide the model with enough flexibility to treat time series with different characteristics. The outputs of the TCN operation are then concatenated as to form a multivariate latent time series {Z}. In particular, WATTNet includes gated convolutions, a standard architectural component for sequential data. Two dilated convolutions are applied to {X} and the results are passed to non-linear activation functions and then multiplied element-wise:\n",
      "\n",
      "Spatial learning: self-attention\n",
      "\n",
      "Attention is a relatively recent development that revolutionized natural language processing and much of the world of deep learning at large. It was originally developed for neural machine translation as a way to determine which information to store or load from the memory module. Its popularity skyrocketed thanks to the seminal paper [4] where Vaswani et al. propose utilizing it as a tool to learn representations. Attention can be as a modified convolution operation; relations between dimensions or elements of its input are learned from a similarity function and there is no binding locality assumption. The output is computed as a convex combinations of the inputs (that is, with weights that sum up to 1) whereas convolutions places no constraints on its multiplicative weights.\n",
      "\n",
      "Self-attention is a popular variety of attention where the same data is used to derive Q, K and V. It can be a useful inductive bias to introduce in the model when the dataset displays a high degree of self-similarity and correlation across dimensions or elements.\n",
      "\n",
      "Over the years, various deep learning models have been developed for spatio-temporal representation learning. One such example are ConvLSTMs [5], which introduce a convolution operation inside the LSTM cell to capture spatio-temporal information. A weakness of ConvLSTMs and similar approaches is given by the prior assumption of structure in the spatial domain where features closer together are prioritized by the convolution operation, as is the case for example with video data. In general applications, the time series are arbitrarily concatenated as input data and locality assumptions do not hold. Self-attention makes no such assumptions; its flexibility to freely attend to different sources of data is behind the success of Transformer-like models, and is also the the computational tool that allows WATTNet to aggregate information across time series in a principled way. More specifically, WATTNet employs a single-head scaled-dot product attention mechanism between dilated dilated convolution layers to exchange information across different input time series at a specific time slice:\n",
      "\n",
      "Deep WATTNet: hierarchical spatio-temporal representation: A single temporal and spatial module constitute a full WATTNet layer of computation and is referred to as WATTBlock. WATTBlocks can be stacked, in which case the spatial module output becomes a hierarchical spatio-temporal representation of the M-dimensional multivariate input. As is the case with other temporal convolution models, the dilation coefficient is doubled each temporal module as to provide an increasing receptive field which allows for a computationally inexpensive way to model long sequences. An additional benefit of the gradual dilation increase is the slow introduction of interaction terms between time series which include less lagged values for early WATTBlocks and more for later ones. We note that gradually increasing the size of this interaction window is key in learning a hierarchical representation of the data that strongly intertwines spatial and temporal causal effects.\n",
      "\n",
      "WATTNet applied to FX trading\n",
      "\n",
      "Following recent trends of successful AI adoption, the financial world has seen a significant surge of attempts at leveraging deep learning and reinforcement learning techniques across various application areas. While the literature has no shortage of works in which reinforcement learning is applied to portfolio management [6] and optimal trade execution, the FX markets remain comparatively unexplored. We are not aware of any published work where deep learning or reinforcement systems are introduced to tackle FX trading in a non-deliverable-forward (NDF) setting. To bridge this gap, and to leverage the richness and high-dimensionality of the data available, we decided to test WATTNet’s performance in a NDF FX trading environment.\n",
      "\n",
      "Non-deliverable-forward trading: Trading in FX markets is generally done via spot exchanges or forward exchanges. An NDF operates similarly to forward exchange contracts and exists as a replacement to forward FX trades in emerging markets. NDF markets are over-the-counter, meaning they operate directly between involved parties without supervision, and are generally more volatile due to limited market-depth. In NDF trades the parties agree on notional amounts of primary and secondary currency (e.g. dollar USD and korean won KRW) which define the forward rate. The currency amounts are not exchanged at the end of the contract: instead, NDF trades are cash-settled in USD, and the cash flow is computed as:\n",
      "\n",
      "where x is the spot rate, a is the tenor and v is the notional amount. Longer tenors are generally more profitable at the expense of a higher volatility, commonly referred to as risk-premia. A successful trading agent thus has to find a difficult balance between risky, high return and safer, low return actions.\n",
      "\n",
      "Experimental results: We constructed a dataset containing 1123 time series as input features to test the effectiveness of WATTNet in settings with highly multivariate data. The data includes spot rates for 64 FX pairs as well as a variety of technical indicators and volume time series for different tenors. The model is trained to match optimal tenor labels extracted from historical data (tenors with highest possible return), with maximum allowed tenor of 90 days.\n",
      "\n",
      "WATTNet outperforms the other baselines by a wide margin and achieves a significant positive return on investment (ROI) in all NDF markets under analysis. In particular, it displays enough flexibility to beat NDF markets with varying degrees of dissimilarity between the training and test periods in terms of volatility and general market regimes such as UDCNY:\n",
      "\n",
      "as well as markets with a more stable trend such as USDPHP:\n",
      "\n",
      "Explainability of the learned strategy\n",
      "\n",
      "Model explainability is particularly important in application areas where the models are tasked with critical decision making, as is the case for algorithmic trading. Understanding driving factors behind a trading decision is necessary to properly assess the risks involved. We tackled this issue with two orthogonal approaches for evaluating the tenor selection strategy in terms of noise stability and driving factors.\n",
      "\n",
      "Feature importance by input gradients: To pinpoint the driving factors of trades at different tenors we propose sorting the input features by their gradient magnitude. In the case of tenor selection, each input feature carries a specific meaning which can be leveraged to confirm whether the model outputs actions consistent with market dynamics.To illustrate the effectiveness of this approach we select 6 spot rate features with highest absolute input gradient values for tenor actions of 90 days in the USDCNY test data, EURSGD, GBPAUD, USDCHF, EURDKK, USDSGD, AUDNZD:\n",
      "\n",
      "The Pearson’s correlation coefficient ρ between USDCNY spot rate and each of the above-listed features is computed from both training and test sets. In the background, 20 day rolling standard deviation highlights regions of low and high volatility. Input sequences which are mapped by the model to tenors of 90 days are colored in red, whereas the exact day where such tenors are chosen are indicated as black dots. The model learns to trade on long tenors when currencies that are positively correlated with USDCNY, such as USDSGD, undergo periods of growth. The degree to which such trends affect the model is directly reflected in ρ: USDCHF, still positively correlated with USDCNY, shows a less decisive positive trend, with additional ups and downs. Moreover, the model learns to favor trading periods with low volatility.This analysis can be extended to additional input features and can boost confidence in the decisions made by the model.\n",
      "\n",
      "Stability via latent representation: Desired properties of the learned trading strategy are input coherence and stability. Input coherence is achieved by a model that outputs similar tenors for similar states. Stability, on the other hand, is concerned with how much noise perturbation is required to cause a tenor switch from a certain state. We performed a visual inspection of these properties via a uniform manifold approximation and projection (UMAP) [6] which excels at capturing both local and global structure of high-dimensional data. For each trained model, latent vectors of their last layer are embedded into two-dimensional space. UMAP outputs compact clusters of labels for input coherent models and more volumetric clusters for stable models:\n",
      "\n",
      "WATTNet learns a coherent latent representation that clusters low and high tenors correctly and covers a larger volume of the embedding space. Instability of GRU and LSTM observed in results table I and II can in part be explained by noticing that their learned representation lies on thin lower-dimensional manifolds with mixed tenor labels. As a result, small noise perturbations can cause wide jumps in tenors, causing a drop in performance.\n",
      "\n",
      "Conclusions\n",
      "\n",
      "We are currently exploring the use of WATTNet as a representation learning module for deeper trading pipelines involving reinforcement learning agents. Additionally, multi-head attention instead of single-head is being tested as an effective modification to WATTNet. The results have been submitted to AAAI20 and an arXiv preprint is available. Scripts to download and preprocess the data, as well as PyTorch code for training and evaluating the models will be made available here for reproducibility purposes. For clarifications or inquiries about the code, contact michael [at] neuri.ai.\n",
      "\n",
      "About the authors:\n",
      "\n",
      "Michael Poli is a research engineer at Neuri Pte Ltd\n",
      "\n",
      "Ilija Ilievski is a research scientist at Neuri Pte Ltd\n",
      "\n",
      "References:\n",
      "\n",
      "[1] Campbell, John Y., et al. The econometrics of financial markets. princeton University press, 1997.\n",
      "\n",
      "[2] Santoro, Adam, et al. “Relational recurrent neural networks.” Advances in Neural Information Processing Systems. 2018.\n",
      "\n",
      "[3] Oord, Aaron van den, et al. “Wavenet: A generative model for raw audio.” arXiv preprint arXiv:1609.03499 (2016).\n",
      "\n",
      "[4] Vaswani, Ashish, et al. “Attention is all you need.” Advances in neural information processing systems. 2017.\n",
      "\n",
      "[5] Xingjian, S. H. I., et al. “Convolutional LSTM network: A machine learning approach for precipitation nowcasting.” Advances in neural information processing systems. 2015.\n",
      "\n",
      "[6] Yu, Pengqian, et al. “Model-based Deep Reinforcement Learning for Dynamic Portfolio Optimization.” arXiv preprint arXiv:1901.08740 (2019).\n",
      "\n",
      "[7] McInnes, Leland, John Healy, and James Melville. “Umap: Uniform manifold approximation and projection for dimension reduction.” arXiv preprint arXiv:1802.03426 (2018).\n",
      "###################\n",
      "Non Performance Requirements of Consumer Data Standards Specification : Open Banking in Australia\n",
      "\n",
      "Dassana Wijesekara·Follow\n",
      "\n",
      "4 min read·Mar 28, 2020\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Consumer Data Standards (CDS) under Consumer Data Right (CDR) defines set of Non-Functional Requirements (NFR) that needs to be met by Data Holders. The NFR attributes and their threashhold values are shown below.\n",
      "\n",
      "In order implement and adhere to these NFR, first we need to understand the end to end request response cycle and then break it down at each step. I’m taking a simple banking API request made by an ADR application to get customer account to understand the components involved and typical response cycle. In order understand the behaviour I will break the journey in to 3 stages as listed below.\n",
      "\n",
      "Public Internet to API Gateway\n",
      "\n",
      "API Gateway and middleware\n",
      "\n",
      "Data source(s)\n",
      "\n",
      "Public Internet to API Gateway\n",
      "\n",
      "Usually an internet facing application is fronted with a firewall (Web Application Firewall). Firewall establishes a barrier between internal secure network and the untrusted external network : public internet. Load balancer sit next to the the Firewall and route traffic based on the routing policies. Component pattern is shown below with their activities listed inside.\n",
      "\n",
      "Usually firewall and load balancer performe extremly fast compared to other components on the request response chain. Having sensible set of rules and depth of analysis, and resources available , response time degradation may be negligible, unnoticeable or in-significant.\n",
      "\n",
      "API Gateway and Middleware\n",
      "\n",
      "After the load balancer the request lands on a API gateway. API gateway throttles the request based on throttling policies and may reject the request if it has reached the throttling limit. As the second step API gateway need to validate the structural conformance of the request and the payload against the CDS specification. Additionally it needs to support the API queries and versions. Because there might be a situation where data holder need to support multiple versions of the data models of CDS specification.\n",
      "\n",
      "API Gateway handover the request to an integration module which extract data from original source or from multiple sources. It aggregates and mediates the information extracted. If you look at the time spent on each of the components less time is spent on API gateway compared to integration component (t0-t1 < t1-t2).\n",
      "\n",
      "Data Sources\n",
      "\n",
      "Data sources seem to run very slow and seem to have performance bottle neck within the data sources.\n",
      "\n",
      "1.0 Achieving Minimum Performance Requirements\n",
      "\n",
      "I have listed minimum round trip time (What ADR experience) from the CDS 1.2.0 specification for each API below.\n",
      "\n",
      "You may notice that getMetrics() API is not in this table. In order to achieve above round trip times we need to improve the data source performance and employ following tactics.\n",
      "\n",
      "Caching Static Data\n",
      "\n",
      "We could target caching product / product details, customer and customer details like static data. Therefore incoming requests may not put load on the data sources. Caching can be enabled at API gateway and as well as on the integration module as shown below.\n",
      "\n",
      "Employing a Data Lake\n",
      "\n",
      "Internal banking systems from core banking to digital banking systems can offload data to a data lake implemented on an infrastructure that has more transaction performance.\n",
      "\n",
      "2.0 Achieving Minimum Availability Requirements\n",
      "\n",
      "CDS 1.2.0 defines availabilty of APIs to be 99.5% per month. This does not include planned down times. This translates in to maximum of 7.2 minutes unplanned down time for a day.\n",
      "\n",
      "Availability can be achieved using HA deployment and multi-data center deployment for on premise deployment.\n",
      "\n",
      "For cloud deployments this can be achieved using multiple availability zones.\n",
      "\n",
      "As an example Microsoft Azure Cloud guarantees uptime of 99.99% for instances deployed in multiple availability zones as shown below in their SLA.\n",
      "\n",
      "AWS guarantees the same level of availability under their SLA as shown below.\n",
      "\n",
      "3.0 Maximum Throttling Requirements\n",
      "\n",
      "Based on CDS 1.2.0 specification following parameters are used set the threshold.\n",
      "\n",
      "Number of sessions per day : the number of individual sessions initiated in a calendar day.\n",
      "\n",
      "Transactions Per Second (TPS) : the number of concurrent transactions each second.\n",
      "\n",
      "Number of calls : the number of end point calls initiated for a specified duration.\n",
      "\n",
      "How thresholds work is shown below.\n"
     ]
    }
   ],
   "source": [
    "print('\\n###################\\n'.join([page.page_content for page in web_content]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:23:15.461575301Z",
     "start_time": "2023-06-03T10:23:15.406445791Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain.text_splitter:Created a chunk of size 553, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 565, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 648, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 993, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 562, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 539, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 651, which is longer than the specified 500\n",
      "WARNING:langchain.text_splitter:Created a chunk of size 1068, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Member-only story\n",
      "\n",
      "Top 10 Architecture Characteristics / Non-Functional Requirements with Cheatsheet\n",
      "\n",
      "Love Sharma·Follow\n",
      "\n",
      "Published inDev Genius·7 min read·Jun 30, 2022\n",
      "\n",
      "ListenShare\n",
      "\n",
      "14\n",
      "\n",
      "-\n",
      "\n",
      "14\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Imagine you are buying a car.\n",
      "\n",
      "What essential features do you need in it?\n",
      "\n",
      "A vehicle should deliver a person from point A to point B.\n",
      "\n",
      "But what we also check in it is Safety, Comfort, Maintainability, Ease of repair or Better mileage.\n",
      "###################\n",
      "You may also look for an electric version or better speed.\n",
      "\n",
      "Why?\n",
      "\n",
      "To limit the surprises which may occur in delivering the primary function, i.e., take a person from Point A to Point B.\n",
      "\n",
      "Similarly, just like a car, motorcycle, or House, the software has its non-functional requirements called “Architectural Characteristics”.\n",
      "\n",
      "Be it a website, a mobile or a desktop app; it should have a set of quality attributes to meet end-user needs.\n",
      "###################\n",
      "Architecture Characteristics / Non-Functional Requirements\n",
      "\n",
      "Briefly, functional requirements define what a system is supposed to do, like in the case of a car, take a person from A to B, and non-functional requirements stipulate how a system is supposed to be.\n",
      "\n",
      "Here is the overall cheatsheet of NFR:\n",
      "\n",
      "https://imgur.com/a/HzPp8s0\n",
      "\n",
      "These top 10 Architectural Characteristics covers most of the aspect of a large-scale project.\n",
      "###################\n",
      "You don’t need to accommodate all in your project; pick the most essential and knock it out.\n",
      "\n",
      "This article is not providing the solution to these NFRs but instead makes you aware of which areas you need to consider when designing a system.Let’s understand each one of them:\n",
      "\n",
      "Scalability:\n",
      "\n",
      "The ability for the system to perform and operate as the number of users or requests increases.\n",
      "\n",
      "Scalability is achievable with Horizontal or vertical scaling of the machine or simply attaching AutoScalingGroup.\n",
      "###################\n",
      "Traffic Pattern: Understand the traffic pattern of the system.\n",
      "\n",
      "It’s not cost-efficient to spawn as many machines as possible, even if it is underutilisation.\n",
      "\n",
      "Diurnal Pattern: Traffic increases in the morning and decreases in the evening for a particular region.\n",
      "\n",
      "Global / Regional: Regional Heavy usage of the application.\n",
      "\n",
      "Thundering Herd: Many users are requesting resources, but only a few machines are available to serve the burst of traffic.\n",
      "###################\n",
      "These could occur during peak time or in densely populated areas.\n",
      "\n",
      "Elasticity: Ability to quickly spawn a few machines to handle the burst of traffic and gracefully shrink when the demand is reducing.\n",
      "\n",
      "Latency: Ability to serve the request as quickly as possible.\n",
      "\n",
      "This also includes optimising the algorithms and replicating the system near users to reduce the round trip of a request.\n",
      "\n",
      "An average google search takes 400 ms.\n",
      "###################\n",
      "Availability\n",
      "\n",
      "It is measured as a percentage of uptime and defines the proportion of time that a system is functional and working.\n",
      "\n",
      "Availability is affected by system errors, infrastructure problems, malicious attacks and system load.\n",
      "\n",
      "Deployment Stamps: Deploy multiple independent copies of application components, including data stores\n",
      "\n",
      "Geodes: Deploy backend services into a set of geographical nodes, each of which can service any client request in any region.\n",
      "###################\n",
      "Extensibility\n",
      "\n",
      "Extensibility measures the ability to extend a system and the effort required to implement the extension.\n",
      "\n",
      "The extension can be through adding new functionality or modifying existing functionality.\n",
      "\n",
      "The principle provides for enhancements without impairing current system functions.\n",
      "###################\n",
      "Modular / Reusability: Reusability, together with extensibility, allows technology to be transferred to another project with less development and maintenance time, as well as enhanced reliability and consistency.\n",
      "\n",
      "Pluggability: Ability to easily plug other components like in the case of microkernel architecture.\n",
      "\n",
      "Consistency\n",
      "\n",
      "Consistency guarantees that every read returns the most recent write.\n",
      "###################\n",
      "This means that after the execution of every operation, the data is consistent across all the nodes, and thus all clients see the same data at the same time, no matter which node they connect to.\n",
      "\n",
      "Consistency improves the data freshness.\n",
      "\n",
      "Resiliency\n",
      "\n",
      "A system can gracefully handle and recover from accidental and malicious failures.\n",
      "\n",
      "Detecting failures and recovering quickly and efficiently is necessary to maintain resiliency.\n",
      "###################\n",
      "Recoverability: The preparatory processes and functionality enable you to return your services to an initial functioning state after an unintended change.\n",
      "\n",
      "Unintended changes include the soft or hard deletion or misconfiguration of applications.\n",
      "###################\n",
      "Disaster Recovery: Disaster recovery (DR) consists of best practices designed to prevent or minimise data loss and business disruption resulting from catastrophic events — everything from equipment failures and localised power outages to cyberattacks, civil emergencies, criminal or military attacks, and natural disasters.\n",
      "\n",
      "Design Patterns:\n",
      "\n",
      "Bulkhead: Isolate elements of an application into pools so that if one fails, the others will continue to function.\n",
      "###################\n",
      "Circuit Breaker: Handle faults that might take a variable amount of time to fix when connecting to a remote service or resource.\n",
      "\n",
      "Leader Election: Coordinate the actions performed by a collection of collaborating task instances in a distributed application by electing one instance as the leader that assumes responsibility for managing the other instances.\n",
      "###################\n",
      "Usability\n",
      "\n",
      "Usability can be described as the capacity of a system to provide a condition for its users to perform the tasks safely, effectively, and efficiently while enjoying the experience.\n",
      "\n",
      "It is the degree to which specified consumers can use software to achieve quantified objectives with effectiveness, efficiency and satisfaction in a quantified context of use.\n",
      "\n",
      "Accessibility: Make the software available to people with the broadest range of characteristics and capabilities.\n",
      "###################\n",
      "This includes users with deaf, blind, colourblindness, etc.\n",
      "\n",
      "Learnability: How easy users can learn how to use the software?\n",
      "\n",
      "API Contract: For Internal teams, understanding the API Contracts can help easily pluggable into any system.\n",
      "\n",
      "Observability\n",
      "\n",
      "Observability is the ability to collect data about program execution, internal states of modules, and communication between components.\n",
      "\n",
      "To improve observability, use various logging and tracing techniques and tools.\n",
      "###################\n",
      "Logging: There are different types of logs generated within each request: event logs, transaction logs, message logs and server logs.\n",
      "\n",
      "Alerts & Monitoring: Prepare monitoring dashboards, create SLI (Service Level Indicators) and set up critical alerts.\n",
      "\n",
      "L1 / L2 / L3: Setup on-call support process for L1 / L2.\n",
      "\n",
      "L1 support includes interacting with customers.\n",
      "\n",
      "L2 support manages the tickets routed to them by L1 and helps troubleshoot.\n",
      "###################\n",
      "L3 is the last line of support and usually comprises a development team which addresses the technical issues.\n",
      "\n",
      "Security\n",
      "\n",
      "Degree the software protects information and data so that people or other products or systems have the degree of data access appropriate to their types and levels of authorisation.\n",
      "###################\n",
      "This family of characteristics includes confidentiality (data is accessible only to those authorised to have access), integrity (the software prevents unauthorised access to or modification of software or information), nonrepudiation (can actions or events be proven to have taken place), accountability (can user actions of a user be traced), and authenticity (verifying the identity of a user).\n",
      "###################\n",
      "Auditability: Audit trails track system activity so that when a security breach occurs, the mechanism and extent of the breach can be determined.\n",
      "\n",
      "Storing audit trails remotely, where they can only be appended, can keep intruders from covering their tracks.\n",
      "\n",
      "Legality:\n",
      "\n",
      "Compliance: Adhere to data protection laws like GDPR, CCPA, SOC2, PIPL or FedRamp.\n",
      "###################\n",
      "Privacy: Ability to hide transactions from internal company employees (encrypted transactions so even DBAs and network architects cannot see them).\n",
      "\n",
      "Authentication: Security requirements to ensure users are who they say they are.\n",
      "\n",
      "Authorisation: Security requirements to ensure users can access only certain functions within the application (by use case, subsystem, webpage, business rule, field level, etc.).\n",
      "###################\n",
      "Durability\n",
      "\n",
      "Durability is the solution ability of software’s serviceability and meet users’ needs for a relatively long time.\n",
      "\n",
      "Replication: involves sharing information to ensure consistency between redundant resources to improve reliability, fault-tolerance, or accessibility.\n",
      "\n",
      "Fault Tolerance: It is the property that enables a system to continue operating correctly in the event of the failure of one or more faults within some of its components.\n",
      "###################\n",
      "Archivability: Will the data need to be archived or deleted after some time?\n",
      "\n",
      "(For example, customer accounts will be deleted after three months or marked as obsolete and archived in a secondary database for future access.)\n",
      "\n",
      "Agility\n",
      "\n",
      "It has become today’s buzzword when describing a contemporary software method.\n",
      "\n",
      "An associate agile team could be a handy team able to befitting reply to changes.\n",
      "\n",
      "Modification is what software development is highly abundant.\n",
      "###################\n",
      "Maintainability: How easy it is to apply changes and enhance the system?\n",
      "\n",
      "— Represents the degree of effectiveness and efficiency to which developers can modify the software to improve it, correct it, or adapt it to changes in environment and requirements.\n",
      "###################\n",
      "Testability: how easily developers and others can test the software\n",
      "\n",
      "Ease of development: the degree to which developers can modify the software without introducing defects or degrading existing product quality\n",
      "\n",
      "Deployability: The time to get code into production after committing the deployment time.\n",
      "\n",
      "Installability: Ease of system installation on all necessary platforms.\n",
      "###################\n",
      "Upgradeability: Ability to easily/quickly upgrade from a previous version of this application/solution to a newer version on servers and clients.\n",
      "\n",
      "Portability: Does the system need to run on more than one platform?\n",
      "\n",
      "(For example, does the frontend need to run against Oracle and SAP DB?\n",
      "\n",
      "Configurability: The end users can easily change aspects of the software’s configuration (through usable interfaces).\n",
      "###################\n",
      "Compatibility: Degree to which a product, system, or component can exchange information with other products, designs, or members and perform its required functions while sharing the same hardware or software environment.\n",
      "\n",
      "Conclusion\n",
      "\n",
      "Now, that you are familiar with the NFRs or Architectural Characteristics, you may be thinking that which one will fit your project needs.\n",
      "\n",
      "Or may be all of them are required in every project.\n",
      "###################\n",
      "So how to proceed with adopting these characteristics within your project?\n",
      "\n",
      "Once you get the functional requirement, try to find the bottleneck in the system which may add obstacle to primary function.\n",
      "\n",
      "And how to find the bottleneck?\n",
      "\n",
      "Try answering few of such questions:\n",
      "\n",
      "Will the system perform in 100M / 1B userbase?\n",
      "\n",
      "Will my system handles 10,000 concurrent request?\n",
      "\n",
      "Am I handling the data in secured way?\n",
      "\n",
      "Can I add more features easily without impacting the existing working features?\n",
      "###################\n",
      "and many more…\n",
      "\n",
      "Some of these questions can help to identify the bottleneck or less performing area which are potential start point to improve the overall reliability of the system.\n",
      "\n",
      "Did I missed anything?\n",
      "\n",
      "If yes, Please help to enrich this article by sharing your thoughts in comments.\n",
      "\n",
      "With that, I conclude this learning; I hope you have learned something new today.\n",
      "\n",
      "Please do share with more colleagues or friends.\n",
      "\n",
      "Finally, Consider becoming a Medium member.\n",
      "\n",
      "Thank you!\n",
      "###################\n",
      "Coding Interview types: ML/Data Science/AI Research Engineer\n",
      "\n",
      "Curated list of types of questions to prepare for\n",
      "\n",
      "Purvanshi Mehta·Follow\n",
      "\n",
      "3 min read·Apr 12, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "2\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "I recently interviewed with Microsoft (Data Scientist ll), Amazon (Applied AI Scientist) and Apple (Software Development : Machine Learning).\n",
      "\n",
      "I wrote about the preparation involved on the Machine Learning side and received a lot of questions about coding questions in interviews.\n",
      "###################\n",
      "These are the major types of questions I was asked.\n",
      "\n",
      "Obviously the difficulty will varying according to the team and the company.\n",
      "\n",
      "Feel free to add more questions!\n",
      "\n",
      "Take home assignments\n",
      "\n",
      "These are my favorite types of tests because you can actually showcase your skills.\n",
      "\n",
      "Here are some of the types of questions I have been asked\n",
      "\n",
      "A dataset will be given and you will need to build Machine Learning models to show how much your model perform on the test data in 24 hours as compared to others.\n",
      "###################\n",
      "The task usually relates to the your everyday job in the company.\n",
      "\n",
      "Basics of probability and statistics questions- I got one question which involved finding some bounds on a custom algorithm and then proving it theoretically.\n",
      "\n",
      "There can be questions for hypothesis testing and interpreting the results.\n",
      "###################\n",
      "Some pointers you can keep in mind for acing such interviews -\n",
      "\n",
      "Put in good documentation for your code\n",
      "\n",
      "Show your Object Oriented programming skills even if you are coding in jupyter notebook and python.\n",
      "\n",
      "Eg.\n",
      "\n",
      "You can have a different visualization module.\n",
      "\n",
      "Have a through Data Analysis part- This shows that you have tried to understand the problem statement.\n",
      "\n",
      "It’s a plus if you include some hypothesis tests in your analysis.\n",
      "###################\n",
      "Standard Data Structure and Algorithms questions\n",
      "\n",
      "These are leetcode type questions.\n",
      "\n",
      "Usually these are not very tough if your team is a bit research oriented or more Machine Learning focused.\n",
      "\n",
      "In fact going through some algorithm and data structure basics should be enough.\n",
      "\n",
      "Be sure you can code a basic problem in 20–30 minutes.\n",
      "\n",
      "Live coding\n",
      "\n",
      "Different companies have different types of live coding sessions and sometimes there can be multiple people evaluating you at the same time.\n",
      "###################\n",
      "These can also be of three types\n",
      "\n",
      "DS / Algo questions- One thing to practice in this part is that you are able to code the basic structure in a few minutes so that you can concentrate on the problem solving more.\n",
      "\n",
      "Eg.\n",
      "\n",
      "Given a graph question be sure to code the main graph class quickly along with some traversal if required.\n",
      "\n",
      "Deep Learning coding- I have been asked to code simple image classification, sequence to sequence model.\n",
      "\n",
      "The interviewer is not checking your syntax but the flow.\n",
      "###################\n",
      "Example you should know how to form a custom dataloader, why you zero the gradients before backpropagating and the type of loss you will use… and so on.\n",
      "\n",
      "Machine learning algorithms coding- I was asked to code random forest followed by bagging and boosting (not kidding here!).\n",
      "\n",
      "I realized the interviewer was only trying to check if I understand the differences and have a direction of how will it be implemented.\n",
      "###################\n",
      "Nonlinear Regression Tutorial with Radial Basis Functions\n",
      "\n",
      "Joseph Gatto·Follow\n",
      "\n",
      "Published inAnalytics Vidhya·4 min read·Mar 23, 2021\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Let's take a look at basis function regression which allows us to model non-linear relationships.\n",
      "\n",
      "If you are familiar with regular linear regression, then you know the goal is to find parameters (α,β) such that we can find the line of best fit y=αx+β.\n",
      "\n",
      "When performing non-linear regression, we are no longer just solving for an equation of a line.\n",
      "###################\n",
      "Now, our high-level goal is to solve for the best linear combination of a set of basis functions that allows us to model something non-linear.\n",
      "\n",
      "In other words, imagine we have some simple dataset\n",
      "\n",
      "Now, suppose we have a set of basis functions that can be anything we want!\n",
      "\n",
      "For RBF regression, we are going to use a collection of Gaussians like this.\n",
      "###################\n",
      "For RBF-based regression, we transform the input with the following kernel\n",
      "\n",
      "Where cₖ is the center/mean of gaussian k and σ is the standard deviation of said gaussian.\n",
      "\n",
      "Each of these are hyperparameters of our model.\n",
      "\n",
      "More specifically, the hyperparameters include 1) how many basis functions 2) where each one is located and 3) The variance of each Gaussian.\n",
      "###################\n",
      "In my example below, I choose the center of each gaussian such that they are evenly spaced along our training data and arbitrarily chose a standard deviation of 1.\n",
      "\n",
      "There may be smarter ways to choose these parameters for other types of problems.\n",
      "\n",
      "To summarize, what we want is to solve for the optimal weights w, so we can best solve y=b(x)ᵗw.\n",
      "\n",
      "We can solve for these parameters the same way we do in regular linear regression.\n",
      "###################\n",
      "Recall that for linear regression, this means solving for parameters w requires we do the following:\n",
      "\n",
      "We can do the same for non-linear regression.\n",
      "\n",
      "Namely,\n",
      "\n",
      "What we are left with is a weight vector with k weights, one for each of our radial basis functions.\n",
      "\n",
      "As we will see, we can then transform any input x into an output y’ as a linear combination of our basis functions.\n",
      "###################\n",
      "Let's take a look at some results using different numbers of basis functions when trying to fit a non-linear RGB regressor to a sin curve\n",
      "\n",
      "As we can see, when we use too few basis functions we are unable to capture the nature of the sin curve.\n",
      "\n",
      "However, for too large a number of basis functions, we severely overfit the data.\n",
      "\n",
      "Sources:\n",
      "\n",
      "http://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/NonlinearRegression.pdf\n",
      "###################\n",
      "WATTNet: Learning to Trade FX with Hierarchical Spatio-Temporal Representations of Highly Multivariate Time Series\n",
      "\n",
      "Neuri Research·Follow\n",
      "\n",
      "Published inneuri-ai·13 min read·Sep 12, 2019\n",
      "\n",
      "ListenShare\n",
      "\n",
      "1\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Financial data is notoriously difficult to model due to non-stationarity, noise and complexity of the underlying dynamics.\n",
      "###################\n",
      "What is often available are merely extremely noisy and incomplete observations of an inaccessible state space; in general, the more sources of data that can be leveraged, the easier it can be to recover the true state of the system, and the longer it can take (computationally).\n",
      "\n",
      "This is the big challenge of time series, in particular the highly multivariate kind.\n",
      "###################\n",
      "Edward Lorenz, MIT mathematician, meteorologist and one of the fathers of the theory of chaos, is known to have concluded “long-term weather forecasting is doomed” after noticing that simulation data across experiments starting at near-identical conditions diverged completely.\n",
      "\n",
      "Recent results have confirmed Lorenz’s estimate: weather forecasting seems to be fundamentally intractable beyond a time horizon of two weeks.\n",
      "###################\n",
      "Financial dynamics are very much similar to weather dynamics: a multitude of highly non-linear factors interact non-linearly to determine future trajectories.\n",
      "\n",
      "Chaotic sensitivity to the slightest perturbations and stochastic terms reliant on unpredictable human behavior corrupt and warp the data and add another layer of complexity to the already challenging problem of predicting the future.\n",
      "###################\n",
      "It is therefore natural to conclude that models capable of capturing inter and intra-dependencies in highly multivariate time series are fundamental in finance.\n",
      "\n",
      "Many, if not most, of such interaction terms are nonlinear and thus challenging to analyze with standard statistical approaches.\n",
      "\n",
      "As Campbell et al.\n",
      "\n",
      "[1] argue:\n",
      "\n",
      "...many aspects of economic behavior may not be linear.\n",
      "###################\n",
      "Experimental evidence and casual introspection suggest that investors' attitudes towards risk and expected return are nonlinear.\n",
      "\n",
      "The terms of many financial contracts such as options and other derivative securities are nonlinear.\n",
      "\n",
      "And the strategic interactions among market participants, the process by which information is incorporated into security prices, and the dynamics of economy-wide fluctuations are all inherently nonlinear.\n",
      "###################\n",
      "Therefore, a natural frontier for financial econometrics is the modeling of nonlinear phenomena.This is quite a challenge, since the collection of nonlinear models is much 'larger' than the collection of linear models—after all, everything which is not linear is nonlinear.\n",
      "\n",
      "Moreover, nonlinear models are generally more difficult to analyze than linear ones, rarely producing closed-form expressions which can be easily manipulated and empirically implemented.\n",
      "###################\n",
      "In some cases, the only mode of analysis is computational, and this is unfamiliar territory to those of us who are accustomed to thinking analytically, intuitively, and linearly.\n",
      "\n",
      "A direct consequence has been the new-found popularity of data-driven models for financial forecasting tasks, in particular recurrent neural networks (RNN) and their variants.\n",
      "###################\n",
      "Recurrent models, while offering an intuitive approach to time series modeling, lack an explicit module to capture inter-dependencies and perform relational reasoning [2].\n",
      "\n",
      "Different approaches to time series modeling rely on temporal convolutions (TCN) as their fundamental computational block.\n",
      "\n",
      "Particularly successful in this area of research is WaveNet [3], originally developed as a generative model for speech data.\n",
      "###################\n",
      "However, vanilla WaveNet and its derivative models are primarily designed to handle univariate time series and are thus ill-suited for highly multivariate financial time series.\n",
      "\n",
      "In this post, we will present an alternative to WaveNet specifically designed for the multivariate case.\n",
      "###################\n",
      "WaveATTentionNet (WATTNet) incorporates computationally efficient dilated convolutions for temporal learning of autoregressive effects and self-attention modules to learn spatial, inter-time series interaction terms.\n",
      "\n",
      "Here is an overview of a WATTNet applied to an M-dimensional multivariate time series {X}:\n",
      "\n",
      "We will present the details in the following sections.\n",
      "###################\n",
      "In particular, we’ll elaborate on the two fundamental components of WATTNet: temporal learning modules, based on dilated convolutions, and spatial modules, based on self-attention.\n",
      "\n",
      "For more updates check our github repository; we will release complete code at a later date.\n",
      "\n",
      "Temporal learning: dilated convolutions\n",
      "\n",
      "Dilated convolutions are essentially convolutions at lower resolutions.\n",
      "###################\n",
      "They offer improved computational efficiency and a method to avoid overfitting potentially noisy high-frequency components at the cost of a loss of information.\n",
      "\n",
      "WaveNet notoriously introduced dilated convolutions in the temporal, 1-dimensional case.\n",
      "###################\n",
      "The dilation coefficient is doubled each layer as an efficient way to extend the temporal receptive field of the model:\n",
      "\n",
      "WATTNet follows the same trend and utilizes temporal dilated convolutions to learn autoregressive terms for each of the input time series.\n",
      "###################\n",
      "Each univariate time series has access to its own set of convolutional weights as temporal convolution operations are carried on independently:\n",
      "\n",
      "Independence between convolutions is necessary to provide the model with enough flexibility to treat time series with different characteristics.\n",
      "\n",
      "The outputs of the TCN operation are then concatenated as to form a multivariate latent time series {Z}.\n",
      "###################\n",
      "In particular, WATTNet includes gated convolutions, a standard architectural component for sequential data.\n",
      "\n",
      "Two dilated convolutions are applied to {X} and the results are passed to non-linear activation functions and then multiplied element-wise:\n",
      "\n",
      "Spatial learning: self-attention\n",
      "\n",
      "Attention is a relatively recent development that revolutionized natural language processing and much of the world of deep learning at large.\n",
      "###################\n",
      "It was originally developed for neural machine translation as a way to determine which information to store or load from the memory module.\n",
      "\n",
      "Its popularity skyrocketed thanks to the seminal paper [4] where Vaswani et al.\n",
      "\n",
      "propose utilizing it as a tool to learn representations.\n",
      "\n",
      "Attention can be as a modified convolution operation; relations between dimensions or elements of its input are learned from a similarity function and there is no binding locality assumption.\n",
      "###################\n",
      "The output is computed as a convex combinations of the inputs (that is, with weights that sum up to 1) whereas convolutions places no constraints on its multiplicative weights.\n",
      "\n",
      "Self-attention is a popular variety of attention where the same data is used to derive Q, K and V. It can be a useful inductive bias to introduce in the model when the dataset displays a high degree of self-similarity and correlation across dimensions or elements.\n",
      "###################\n",
      "Over the years, various deep learning models have been developed for spatio-temporal representation learning.\n",
      "\n",
      "One such example are ConvLSTMs [5], which introduce a convolution operation inside the LSTM cell to capture spatio-temporal information.\n",
      "\n",
      "A weakness of ConvLSTMs and similar approaches is given by the prior assumption of structure in the spatial domain where features closer together are prioritized by the convolution operation, as is the case for example with video data.\n",
      "###################\n",
      "In general applications, the time series are arbitrarily concatenated as input data and locality assumptions do not hold.\n",
      "\n",
      "Self-attention makes no such assumptions; its flexibility to freely attend to different sources of data is behind the success of Transformer-like models, and is also the the computational tool that allows WATTNet to aggregate information across time series in a principled way.\n",
      "###################\n",
      "More specifically, WATTNet employs a single-head scaled-dot product attention mechanism between dilated dilated convolution layers to exchange information across different input time series at a specific time slice:\n",
      "\n",
      "Deep WATTNet: hierarchical spatio-temporal representation: A single temporal and spatial module constitute a full WATTNet layer of computation and is referred to as WATTBlock.\n",
      "###################\n",
      "WATTBlocks can be stacked, in which case the spatial module output becomes a hierarchical spatio-temporal representation of the M-dimensional multivariate input.\n",
      "\n",
      "As is the case with other temporal convolution models, the dilation coefficient is doubled each temporal module as to provide an increasing receptive field which allows for a computationally inexpensive way to model long sequences.\n",
      "###################\n",
      "An additional benefit of the gradual dilation increase is the slow introduction of interaction terms between time series which include less lagged values for early WATTBlocks and more for later ones.\n",
      "\n",
      "We note that gradually increasing the size of this interaction window is key in learning a hierarchical representation of the data that strongly intertwines spatial and temporal causal effects.\n",
      "###################\n",
      "WATTNet applied to FX trading\n",
      "\n",
      "Following recent trends of successful AI adoption, the financial world has seen a significant surge of attempts at leveraging deep learning and reinforcement learning techniques across various application areas.\n",
      "\n",
      "While the literature has no shortage of works in which reinforcement learning is applied to portfolio management [6] and optimal trade execution, the FX markets remain comparatively unexplored.\n",
      "###################\n",
      "We are not aware of any published work where deep learning or reinforcement systems are introduced to tackle FX trading in a non-deliverable-forward (NDF) setting.\n",
      "\n",
      "To bridge this gap, and to leverage the richness and high-dimensionality of the data available, we decided to test WATTNet’s performance in a NDF FX trading environment.\n",
      "\n",
      "Non-deliverable-forward trading: Trading in FX markets is generally done via spot exchanges or forward exchanges.\n",
      "###################\n",
      "An NDF operates similarly to forward exchange contracts and exists as a replacement to forward FX trades in emerging markets.\n",
      "\n",
      "NDF markets are over-the-counter, meaning they operate directly between involved parties without supervision, and are generally more volatile due to limited market-depth.\n",
      "\n",
      "In NDF trades the parties agree on notional amounts of primary and secondary currency (e.g.\n",
      "\n",
      "dollar USD and korean won KRW) which define the forward rate.\n",
      "###################\n",
      "The currency amounts are not exchanged at the end of the contract: instead, NDF trades are cash-settled in USD, and the cash flow is computed as:\n",
      "\n",
      "where x is the spot rate, a is the tenor and v is the notional amount.\n",
      "\n",
      "Longer tenors are generally more profitable at the expense of a higher volatility, commonly referred to as risk-premia.\n",
      "\n",
      "A successful trading agent thus has to find a difficult balance between risky, high return and safer, low return actions.\n",
      "###################\n",
      "Experimental results: We constructed a dataset containing 1123 time series as input features to test the effectiveness of WATTNet in settings with highly multivariate data.\n",
      "\n",
      "The data includes spot rates for 64 FX pairs as well as a variety of technical indicators and volume time series for different tenors.\n",
      "\n",
      "The model is trained to match optimal tenor labels extracted from historical data (tenors with highest possible return), with maximum allowed tenor of 90 days.\n",
      "###################\n",
      "WATTNet outperforms the other baselines by a wide margin and achieves a significant positive return on investment (ROI) in all NDF markets under analysis.\n",
      "###################\n",
      "In particular, it displays enough flexibility to beat NDF markets with varying degrees of dissimilarity between the training and test periods in terms of volatility and general market regimes such as UDCNY:\n",
      "\n",
      "as well as markets with a more stable trend such as USDPHP:\n",
      "\n",
      "Explainability of the learned strategy\n",
      "\n",
      "Model explainability is particularly important in application areas where the models are tasked with critical decision making, as is the case for algorithmic trading.\n",
      "###################\n",
      "Understanding driving factors behind a trading decision is necessary to properly assess the risks involved.\n",
      "\n",
      "We tackled this issue with two orthogonal approaches for evaluating the tenor selection strategy in terms of noise stability and driving factors.\n",
      "\n",
      "Feature importance by input gradients: To pinpoint the driving factors of trades at different tenors we propose sorting the input features by their gradient magnitude.\n",
      "###################\n",
      "In the case of tenor selection, each input feature carries a specific meaning which can be leveraged to confirm whether the model outputs actions consistent with market dynamics.To illustrate the effectiveness of this approach we select 6 spot rate features with highest absolute input gradient values for tenor actions of 90 days in the USDCNY test data, EURSGD, GBPAUD, USDCHF, EURDKK, USDSGD, AUDNZD:\n",
      "\n",
      "The Pearson’s correlation coefficient ρ between USDCNY spot rate and each of the above-listed features is computed from both training and test sets.\n",
      "###################\n",
      "In the background, 20 day rolling standard deviation highlights regions of low and high volatility.\n",
      "\n",
      "Input sequences which are mapped by the model to tenors of 90 days are colored in red, whereas the exact day where such tenors are chosen are indicated as black dots.\n",
      "\n",
      "The model learns to trade on long tenors when currencies that are positively correlated with USDCNY, such as USDSGD, undergo periods of growth.\n",
      "###################\n",
      "The degree to which such trends affect the model is directly reflected in ρ: USDCHF, still positively correlated with USDCNY, shows a less decisive positive trend, with additional ups and downs.\n",
      "\n",
      "Moreover, the model learns to favor trading periods with low volatility.This analysis can be extended to additional input features and can boost confidence in the decisions made by the model.\n",
      "###################\n",
      "Stability via latent representation: Desired properties of the learned trading strategy are input coherence and stability.\n",
      "\n",
      "Input coherence is achieved by a model that outputs similar tenors for similar states.\n",
      "\n",
      "Stability, on the other hand, is concerned with how much noise perturbation is required to cause a tenor switch from a certain state.\n",
      "###################\n",
      "We performed a visual inspection of these properties via a uniform manifold approximation and projection (UMAP) [6] which excels at capturing both local and global structure of high-dimensional data.\n",
      "\n",
      "For each trained model, latent vectors of their last layer are embedded into two-dimensional space.\n",
      "###################\n",
      "UMAP outputs compact clusters of labels for input coherent models and more volumetric clusters for stable models:\n",
      "\n",
      "WATTNet learns a coherent latent representation that clusters low and high tenors correctly and covers a larger volume of the embedding space.\n",
      "\n",
      "Instability of GRU and LSTM observed in results table I and II can in part be explained by noticing that their learned representation lies on thin lower-dimensional manifolds with mixed tenor labels.\n",
      "###################\n",
      "As a result, small noise perturbations can cause wide jumps in tenors, causing a drop in performance.\n",
      "\n",
      "Conclusions\n",
      "\n",
      "We are currently exploring the use of WATTNet as a representation learning module for deeper trading pipelines involving reinforcement learning agents.\n",
      "\n",
      "Additionally, multi-head attention instead of single-head is being tested as an effective modification to WATTNet.\n",
      "\n",
      "The results have been submitted to AAAI20 and an arXiv preprint is available.\n",
      "###################\n",
      "Scripts to download and preprocess the data, as well as PyTorch code for training and evaluating the models will be made available here for reproducibility purposes.\n",
      "\n",
      "For clarifications or inquiries about the code, contact michael [at] neuri.ai.\n",
      "\n",
      "About the authors:\n",
      "\n",
      "Michael Poli is a research engineer at Neuri Pte Ltd\n",
      "\n",
      "Ilija Ilievski is a research scientist at Neuri Pte Ltd\n",
      "\n",
      "References:\n",
      "\n",
      "[1] Campbell, John Y., et al.\n",
      "\n",
      "The econometrics of financial markets.\n",
      "\n",
      "princeton University press, 1997.\n",
      "###################\n",
      "[2] Santoro, Adam, et al.\n",
      "\n",
      "“Relational recurrent neural networks.” Advances in Neural Information Processing Systems.\n",
      "\n",
      "2018.\n",
      "\n",
      "[3] Oord, Aaron van den, et al.\n",
      "\n",
      "“Wavenet: A generative model for raw audio.” arXiv preprint arXiv:1609.03499 (2016).\n",
      "\n",
      "[4] Vaswani, Ashish, et al.\n",
      "\n",
      "“Attention is all you need.” Advances in neural information processing systems.\n",
      "\n",
      "2017.\n",
      "\n",
      "[5] Xingjian, S. H. I., et al.\n",
      "###################\n",
      "“Convolutional LSTM network: A machine learning approach for precipitation nowcasting.” Advances in neural information processing systems.\n",
      "\n",
      "2015.\n",
      "\n",
      "[6] Yu, Pengqian, et al.\n",
      "\n",
      "“Model-based Deep Reinforcement Learning for Dynamic Portfolio Optimization.” arXiv preprint arXiv:1901.08740 (2019).\n",
      "\n",
      "[7] McInnes, Leland, John Healy, and James Melville.\n",
      "\n",
      "“Umap: Uniform manifold approximation and projection for dimension reduction.” arXiv preprint arXiv:1802.03426 (2018).\n",
      "###################\n",
      "Non Performance Requirements of Consumer Data Standards Specification : Open Banking in Australia\n",
      "\n",
      "Dassana Wijesekara·Follow\n",
      "\n",
      "4 min read·Mar 28, 2020\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Consumer Data Standards (CDS) under Consumer Data Right (CDR) defines set of Non-Functional Requirements (NFR) that needs to be met by Data Holders.\n",
      "\n",
      "The NFR attributes and their threashhold values are shown below.\n",
      "###################\n",
      "In order implement and adhere to these NFR, first we need to understand the end to end request response cycle and then break it down at each step.\n",
      "\n",
      "I’m taking a simple banking API request made by an ADR application to get customer account to understand the components involved and typical response cycle.\n",
      "\n",
      "In order understand the behaviour I will break the journey in to 3 stages as listed below.\n",
      "###################\n",
      "Public Internet to API Gateway\n",
      "\n",
      "API Gateway and middleware\n",
      "\n",
      "Data source(s)\n",
      "\n",
      "Public Internet to API Gateway\n",
      "\n",
      "Usually an internet facing application is fronted with a firewall (Web Application Firewall).\n",
      "\n",
      "Firewall establishes a barrier between internal secure network and the untrusted external network : public internet.\n",
      "\n",
      "Load balancer sit next to the the Firewall and route traffic based on the routing policies.\n",
      "\n",
      "Component pattern is shown below with their activities listed inside.\n",
      "###################\n",
      "Usually firewall and load balancer performe extremly fast compared to other components on the request response chain.\n",
      "\n",
      "Having sensible set of rules and depth of analysis, and resources available , response time degradation may be negligible, unnoticeable or in-significant.\n",
      "\n",
      "API Gateway and Middleware\n",
      "\n",
      "After the load balancer the request lands on a API gateway.\n",
      "\n",
      "API gateway throttles the request based on throttling policies and may reject the request if it has reached the throttling limit.\n",
      "###################\n",
      "As the second step API gateway need to validate the structural conformance of the request and the payload against the CDS specification.\n",
      "\n",
      "Additionally it needs to support the API queries and versions.\n",
      "\n",
      "Because there might be a situation where data holder need to support multiple versions of the data models of CDS specification.\n",
      "\n",
      "API Gateway handover the request to an integration module which extract data from original source or from multiple sources.\n",
      "###################\n",
      "It aggregates and mediates the information extracted.\n",
      "\n",
      "If you look at the time spent on each of the components less time is spent on API gateway compared to integration component (t0-t1 < t1-t2).\n",
      "\n",
      "Data Sources\n",
      "\n",
      "Data sources seem to run very slow and seem to have performance bottle neck within the data sources.\n",
      "\n",
      "1.0 Achieving Minimum Performance Requirements\n",
      "\n",
      "I have listed minimum round trip time (What ADR experience) from the CDS 1.2.0 specification for each API below.\n",
      "###################\n",
      "You may notice that getMetrics() API is not in this table.\n",
      "\n",
      "In order to achieve above round trip times we need to improve the data source performance and employ following tactics.\n",
      "\n",
      "Caching Static Data\n",
      "\n",
      "We could target caching product / product details, customer and customer details like static data.\n",
      "\n",
      "Therefore incoming requests may not put load on the data sources.\n",
      "\n",
      "Caching can be enabled at API gateway and as well as on the integration module as shown below.\n",
      "###################\n",
      "Employing a Data Lake\n",
      "\n",
      "Internal banking systems from core banking to digital banking systems can offload data to a data lake implemented on an infrastructure that has more transaction performance.\n",
      "\n",
      "2.0 Achieving Minimum Availability Requirements\n",
      "\n",
      "CDS 1.2.0 defines availabilty of APIs to be 99.5% per month.\n",
      "\n",
      "This does not include planned down times.\n",
      "\n",
      "This translates in to maximum of 7.2 minutes unplanned down time for a day.\n",
      "###################\n",
      "Availability can be achieved using HA deployment and multi-data center deployment for on premise deployment.\n",
      "\n",
      "For cloud deployments this can be achieved using multiple availability zones.\n",
      "\n",
      "As an example Microsoft Azure Cloud guarantees uptime of 99.99% for instances deployed in multiple availability zones as shown below in their SLA.\n",
      "\n",
      "AWS guarantees the same level of availability under their SLA as shown below.\n",
      "###################\n",
      "3.0 Maximum Throttling Requirements\n",
      "\n",
      "Based on CDS 1.2.0 specification following parameters are used set the threshold.\n",
      "\n",
      "Number of sessions per day : the number of individual sessions initiated in a calendar day.\n",
      "\n",
      "Transactions Per Second (TPS) : the number of concurrent transactions each second.\n",
      "\n",
      "Number of calls : the number of end point calls initiated for a specified duration.\n",
      "\n",
      "How thresholds work is shown below.\n",
      "###################\n",
      "AI Alignment and Safety\n",
      "\n",
      "Why Robustness is not Enough for Safety and Security in Machine Learning\n",
      "\n",
      "Christian Kästner·Follow\n",
      "\n",
      "Published inTowards Data Science·14 min read·Jan 6, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Researchers in multiple communities (machine learning, formal methods, programming languages, security, software engineering) have embraced research on model robustness, typically cast as safety or security verification.\n",
      "###################\n",
      "They make continuous and impressive progress toward better, more scalable, or more accurate techniques to assess robustness and prove theorems, but the many papers I have read in the field essentially never talk about how this would be used to actually make a system safer.\n",
      "###################\n",
      "I argue that this is an example of the streetlight effect: We focus research on robustness verification, because it has well-defined measures to evaluate papers,whereas actual safety and security questions are much harder and require to consider the entire system, not just properties of the model.\n",
      "\n",
      "When thinking of testing, safety and security of production machine learning systems, we need to step beyond narrow measures of robustness.\n",
      "###################\n",
      "From Adversarial Examples to Robustness\n",
      "\n",
      "We have probably all seen examples of how easily machine learning models can be fooled into making wrong predictions by adding slight noise to the input that may be imperceptible to humans, such as this panda recognized (with high confidence) as a gibbon when some minor noise that’s pretty much invisible to humans is added:\n",
      "\n",
      "OpenAI\n",
      "\n",
      "In a nutshell, the problem occurs, because we learn and use models without understanding how they work internally and whether they actually learn concepts that would mirror human cognition.\n",
      "###################\n",
      "The models tend to work on average (as our accuracy measures indicate during model evaluation), but we often really do not know why and how — and maybe we don’t care as long as they mostly work.\n",
      "\n",
      "However, since we don’t know and cannot specify how these models work, we can always find examples of wrong predictions, where the model simply does not produce the expected result.\n",
      "###################\n",
      "Worse, with suitable search, it is often possible to find small variations of a specific input that change the model’s prediction.\n",
      "\n",
      "This is known as adversarial examples, and there is a huge amount of research on how to find them, with and without access to the model’s internals.\n",
      "\n",
      "While the panda-gibbon example might look fun, it is easy to reframe adversarial examples as safety and security problems.\n",
      "###################\n",
      "For examples, researchers have shown that small stickers taped to a stop sign can fool a vision system to recognize the sign as a “Speed Limit 45” sign, implying that this might lead to wrong and dangerous actions taken by an autonomous car:\n",
      "\n",
      "CVPR 2018 paper\n",
      "\n",
      "Beyond intentional attacks by manipulating inputs, also natural changes to inputs may lead to wrong predictions with safety consequences.\n",
      "###################\n",
      "The most common examples are self-driving cars driving in foggy weather conditions or with a slightly titled or smeared camera, all resulting in small modifications of the input.\n",
      "###################\n",
      "For example, researchers have shown how simple transformations of the image (mirroring possible real-world problems) can lead to wrong predictions of the car’s steering angle:\n",
      "\n",
      "DeepTest ICSE 2018 paper\n",
      "\n",
      "In this context, robustness is the idea that a model’s prediction is stable to small variations in the input, hopefully because it’s prediction is based on reliable abstractions of the real task that mirror how a human would perform the task.\n",
      "###################\n",
      "That is, small invisible noise should not flip the prediction from panda to gibbon, small additions to the image should not prevent the model from recognizing a stop sign, and weather conditions or slightly titling the camera should not affect the steering angle of a self-driving car.\n",
      "\n",
      "Making machine learning robust against adversarial inputs.\n",
      "###################\n",
      "Side note: I like Goodfellow et al.’s visual explanation of adversarial examples as a mismatch between the actual decision boundary (ground truth/specification) and the model’s learned decision boundary.\n",
      "\n",
      "Unfortunately, we use machine learning exactly because we don’t have a clear specification and don’t know the actual decision boundary (see my discussion of specifications in Machine Learning is Requirements Engineering).\n",
      "###################\n",
      "Hence the explanation is a nice conceptual view, but not very helpful in a practical setting, where we care about whether a prediction is correct.\n",
      "\n",
      "Robustness relates only to the question whether we are near the model’s decision boundary, without knowing anything about the actual decision boundary.\n",
      "###################\n",
      "Defining Robustness\n",
      "\n",
      "Robustness is an appealing property to study, because it is easy to define well as an invariant over the relation of two inputs (technically a metamorphic relation) without having to rely on specifications and ground truth of what the actual correct prediction is.\n",
      "\n",
      "The way the distance is defined may differ a lot based on the problem.\n",
      "###################\n",
      "Typical examples allow for low amounts of noise to all input features (e.g., all pixels), arbitrary changes to few input features (e.g., change any three pixels), or more complicated transformations (e.g., tilting the picture or adding “fog”).\n",
      "\n",
      "Whatever the possible transformations or corresponding distance functions and maximum distance, we always reason about some neighborhood around the original input.\n",
      "###################\n",
      "Note that this definition does not require any information about what the correct prediction for f(x) or f(x’) is, we simply reason about the fact that the prediction shall stay consistent (whether correct or not) within a neighborhood.\n",
      "###################\n",
      "Robustness is either established as a binary property, i.e., an input for a model is verified as robust or not (usually conservative overapproximations, but also probabilistic judgments with a confidence level have been proposed), or as some form of relative measure, e.g., the distance to the nearest adversarial example or the percentage of robust inputs in the neighborhood.\n",
      "###################\n",
      "Researchers now developed many different search and verification strategies to evaluate this robustness property for deep neural networks.\n",
      "\n",
      "This can be done by searching for adversarial examples within the neighborhood, by simply sampling and testing a large number of data points in the neighborhood, or by different forms of formal verification that formally prove that no point in the neighborhood can change the prediction result.\n",
      "###################\n",
      "Notice that robustness research focuses essentially exclusively on deep neural networks, because this is where it is hard to scale proof techniques.\n",
      "\n",
      "In contrast, I’m not aware of robustness papers on decision tress or linear models and it seems that robustness evaluations would be fairly straightforward to implement and fairly scalable for many such models — I suspect that’s why I haven’t seen such papers.\n",
      "###################\n",
      "In addition to local robustness, some researchers have also discussed a global robustness property of a model, typically some form of average robustness for all possible inputs.\n",
      "\n",
      "For example, one could measure for what percent of inputs robustness can be verified or what the average distance is from each input to the nearest adversarial example.\n",
      "\n",
      "Side note: As studied by Borg et al.\n",
      "###################\n",
      ": Robustness is a term that practitioners use a lot, but usually just vaguely referring to correctness or trustworthiness of the model’s predictions, not the formal notion of robustness studied in the research literature and discussed here.\n",
      "\n",
      "Is Robustness Useful?\n",
      "###################\n",
      "I have read dozens of papers analyzing robustness of machine-learned models and most of them motivate the analysis with safety and security concerns — yet none of those papers discussed or even evaluate how robustness would be really used in a practical setting.\n",
      "\n",
      "First of all, robustness is difficult to interpret.\n",
      "\n",
      "The only model that is fully robust for all inputs is the trivial model that returns the same prediction for all outputs.\n",
      "###################\n",
      "For all other models, there is a decision boundary and some inputs will be close to the model’s decision boundary and hence not robust: some parts of the neighborhood of inputs near the decision boundary will be on each side of the decision boundary.\n",
      "\n",
      "Use case 1: Evaluating robustness at inference time\n",
      "\n",
      "The most plausible usage scenario seems to be to evaluate robustness at inference time, that is, check whether a given prediction made by a system during its operation is robust.\n",
      "###################\n",
      "For example, when labeling images, we could only label those images for which we have proof or confidence that the label is robust to minor perturbations (independent of the confidence score the model may already provide) and thus decide not abstain from labeling the panda in the image above.\n",
      "\n",
      "Similarly, we could identify that the stop sign is not robustly identified as a stop sign and thus not trust it as any sign for decisions made by the self-driving car.\n",
      "###################\n",
      "This seems appealing and robustness can be a powerful tool, but to actually use it for safety and security of systems, engineers need to solve multiple additional problems:\n",
      "\n",
      "Costly analysis: State of the art robustness analysis for deep neural networks is very costly.\n",
      "\n",
      "Even though techniques get better, they currently scale only to small and mid-sized neural networks (handwritten digit recognition anyone?)\n",
      "###################\n",
      "and they typically take minutes to analyze robustness of a single input, due to the cost of the formal analysis, the SMT solving, or the huge number of samples needed.\n",
      "\n",
      "We can certainly hope for research progress to continue to reduce the cost, but it’s hard for me to imagine anybody to use robustness evaluations any time soon at inference time; not for high-volume systems like tagging photos at Facebook and certainly not for real-time applications as self-driving cars.\n",
      "###################\n",
      "Defining maximal distance: Defining a suitable distance function and threshold for the size and shape of the neighborhood is a nontrivial engineering problem.\n",
      "\n",
      "The larger the neighborhood, the more predictions will be classified as not robust.\n",
      "\n",
      "If the neighborhood is too small, attacks and accidental misclassifications are more likely to slip through.\n",
      "\n",
      "Also what perturbations are plausible to occur in practice due to accidents or attacks and how to define the right neighborhood?\n",
      "###################\n",
      "What are the worst cases we want to protect against?\n",
      "\n",
      "Identifying the right distance function and maximum distance threshold are nontrivial engineering challenges.\n",
      "\n",
      "Robust≠safe: If we analyze robustness at inference time and we have found a reasonable maximal distance, what do we do with model predictions that determined as being not robust?\n",
      "\n",
      "We could simply decide not to label the image, but we cannot just stop steering the self-driving car.\n",
      "###################\n",
      "Also, are we assuming that a prediction will be correct, just because it is robust?\n",
      "\n",
      "We clearly need to think about safety mechanisms beyond the model, still anticipating that the model may make wrong predictions or simply indicate more often that it is not sure.\n",
      "\n",
      "Notice that the cost argument may not apply to simpler ML models such as decision trees, though I have not seen anybody discuss using robustness at inference time for those either.\n",
      "###################\n",
      "I would really be interested in seeing projects that try to design safe systems and discussions how they address these challenges.\n",
      "\n",
      "Use case 2: Global model assessment\n",
      "\n",
      "It is possible to evaluate the average robustness of a model for arbitrary inputs, measured as some global robustness property.\n",
      "###################\n",
      "We might consider this as an additional measure of model quality, in addition to prediction accuracy (ROC, recall/precision, lift, MAPE, whatever), where robustness and accuracy measure very different qualities.\n",
      "\n",
      "Note that the evaluation can be done entirely offline; cost may be high, but this strategy does not slow down model inference in production.\n",
      "###################\n",
      "A model that is on average more robust may be preferable, because it may be assumed to learn more actual concepts, be restricted to fewer simpler decision boundaries, or may be affected less by noise or attacks.\n",
      "\n",
      "Challenges now come from how to measure and meaningfully interpret global robustness.\n",
      "\n",
      "Do we really care about all inputs equally, or shall robustness focus on more common inputs?\n",
      "###################\n",
      "For example, many approaches have been used to generate synthetic “test” inputs that are not robust, but do we really care about random inputs that do not resemble any real-world inputs?\n",
      "\n",
      "Also similar to accuracy measures, what level of robustness is considered good?\n",
      "\n",
      "What neighborhood size should be used?\n",
      "\n",
      "How would we make tradeoffs between accuracy and robustness?\n",
      "\n",
      "Overall, global model robustness is easy to define as a metric, but it is unclear how to make use of that metric.\n",
      "###################\n",
      "And finally, say we have established high average robustness, how does this help us make any safety or security claims?\n",
      "\n",
      "We hope that the model makes fewer mistakes or is harder to attack, but we do not know anything about a specific prediction at inference time.\n",
      "\n",
      "In a practical setting, an attacker may very well be able to find adversarial examples for many actual inputs.\n",
      "###################\n",
      "Use case 3: Debugging the model\n",
      "\n",
      "Instead of evaluating robustness globally (use case 2), we can evaluate robustness of a set of actual inputs.\n",
      "\n",
      "For example, we could evaluate the robustness of every single input in the validation data set (hopefully representative of actual inputs in production) or even in the training set.\n",
      "###################\n",
      "We could also analyze robustness of a sample of inputs received in the production system, say, random inputs or inputs flagged as problematic through the system’s telemetry (e.g., users reported predictions as incorrect).\n",
      "\n",
      "Knowing whether certain predictions on sample inputs are robust may help us with debugging.\n",
      "###################\n",
      "We might identify areas of inputs for which many predictions are not robust — either because they are truly close to the real decision boundary or, more likely, because the model is simply not very good at understanding these inputs.\n",
      "\n",
      "We might identify dangerous conditions, such as the inability of our model to deal with fog — hopefully identified during testing not in production.\n",
      "\n",
      "If we understand problems of the model, we may then try to improve the model.\n",
      "###################\n",
      "The most common strategy seems to be data augmentation, where inputs from the neighborhood of training inputs are added to the training data.\n",
      "\n",
      "Changes to the model architecture or feature engineering may also help to nudge the model to learn more relevant concepts.\n",
      "\n",
      "Many many papers explore different approaches here.\n",
      "\n",
      "Overall, this seems a promising strategy to debug, harden, and generally improve models.\n",
      "###################\n",
      "A key challenge is the question of which inputs should be used for robustness analysis (leading to hard questions about curating a good test set) and, as above, how to define the maximum distance to consider.\n",
      "\n",
      "Also similar to use case 2, we won’t have any robustness guarantees about how the model behaves in production.\n",
      "\n",
      "None of this improves a system’s safety or security by itself.\n",
      "###################\n",
      "Going beyond the model: Safety is a system property\n",
      "\n",
      "Safety and security are system properties, not properties of software or machine-learned models.\n",
      "\n",
      "As safety research Nancy Leveson (MIT) puts (repeatedly) it in her ICSE’20 keynote talk:\n",
      "\n",
      "“Software is not unsafe.\n",
      "\n",
      "It can contribute to a hazard, but it does not explode, catch on fire, involve toxic materials, etc.\n",
      "\n",
      "If it is not about hazards, it is not about safety.\n",
      "\n",
      "[…] Software is not unsafe; the control signals it generates can be.\n",
      "###################\n",
      "[…] It is not possible to look at software alone and determine safety […] Virtually all software-related accidents have resulted from unsafe requirements, not software design/implementation errors.”\n",
      "\n",
      "Safety is all about building safe systems, often from unreliable components, including software and hardware components.\n",
      "###################\n",
      "It is about making sure that the system overall is safe, even if a component fails (e.g., hardware failure, a model makes a wrong prediction) or unanticipated interactions arise among multiple components.\n",
      "\n",
      "Given that we cannot specify the expected behavior of a machine-learned model and cannot verify it’s functional correctness, the safety question must concern how the system interacts with the environment based on outputs from machine-learned models that are often unreliable.\n",
      "###################\n",
      "We must think about safeguards outside the model, such as a thermal fuse or maximal toasting duration in a smart toaster that ensures that the toaster does not catch fire no matter what it’s internal model predicts as toasting times.\n",
      "\n",
      "Engineering safe systems requires understanding requirements at the system level, analyzing the interactions between the world and the machine, as well as understanding the interactions of various (possibly unreliable) components.\n",
      "###################\n",
      "It is the context of how the model is used that determines whether the model is safe.\n",
      "\n",
      "Model robustness does ensures neither safety nor security itself.\n",
      "\n",
      "Robustness ensures nothing about “correctness” of a model: robust predictions can still be wrong; a very robust model can be completely useless.\n",
      "###################\n",
      "Robustness may be a useful building block in a larger safety story (with all the open engineering challenges discussed above), since it changes assumptions we can make about an ML component when we consider interactions with other parts of the system and the environment.\n",
      "\n",
      "But only making a model robust does not make the system safe.\n",
      "###################\n",
      "There is research work on building safe systems with machine-learned models, especially around avionics and self-driving cars—it’s all about requirements and system design and system-level testing, whereas assuring a formal robustness property usually does not seem to be much of a concerns there.\n",
      "###################\n",
      "Aleksandar Pasaric)\n",
      "\n",
      "So back to the streetlight effect, (named after the story of a man searching his wallet under a streetlight and when asked “Is this where you lost your wallet” replies that he lost it elsewhere, but it’s easier to search here where the light is): Robustness of deep neural networks is a thankful research topic because it is well defined, challenging, with room for clearly measurable improvements over the state of the art.\n",
      "\n",
      "Many researchers have made incredible contributions.\n",
      "###################\n",
      "However, if we are really concerned about safety and security of production systems with machine-learning components, we should look beyond the simple and well-defined problems at the real and ugly engineering challenges of real-world systems.\n",
      "###################\n",
      "Further readings:\n",
      "\n",
      "My prior posts on quality assurance of ML-enabled systems: Machine Learning is Requirements Engineering (on the notion of correctness and the role of specifications), A Software Testing View on Machine Learning Model Quality (on testing strategies beyond accuracy), The World and the Machine and Responsible Machine Learning (on system-level thinking and requirements engineering)\n",
      "\n",
      "Paper surveying safety engineering for ML systems in current automotive engineering: Borg, Markus, Cristofer Englund, Krzysztof Wnuk, Boris Duran, Christoffer Levandowski, Shenjian Gao, Yanwen Tan, Henrik Kaijser, Henrik Lönn, and Jonas Törnqvist.\n",
      "###################\n",
      "“Safely entering the deep: A review of verification and validation for machine learning and a challenge elicitation in the automotive industry.” Journal of Automotive Software Engineering.\n",
      "\n",
      "Volume 1, Issue 1, Pages 1–19.\n",
      "\n",
      "2019\n",
      "\n",
      "Paper on safety engineering and architectural safety patterns for autonomous vehicles: Salay, Rick, and Krzysztof Czarnecki.\n",
      "###################\n",
      "“Using machine learning safely in automotive software: An assessment and adaption of software process requirements in ISO 26262.” arXiv preprint arXiv:1808.01614 (2018).\n",
      "\n",
      "Another paper discussing different safety strategies for autonomous vehicles: Mohseni, Sina, Mandar Pitale, Vasu Singh, and Zhangyang Wang.\n",
      "\n",
      "“Practical Solutions for Machine Learning Safety in Autonomous Vehicles.” SafeAI workshop at AAAI’20, (2020).\n",
      "###################\n",
      "Survey paper listing many recent robustness verification techniques (in Sec 4): Huang, Xiaowei, Daniel Kroening, Wenjie Ruan, James Sharp, Youcheng Sun, Emese Thamo, Min Wu, and Xinping Yi.\n",
      "\n",
      "“A survey of safety and trustworthiness of deep neural networks: Verification, testing, adversarial attack and defence, and interpretability.” Computer Science Review 37 (2020).\n",
      "\n",
      "Annotated bibliography on software engineering for AI-enabled systems including several papers on robustness, security, and safety\n",
      "###################\n",
      "Interview resources : ML/Data Science/AI Research Engineer\n",
      "\n",
      "A curated list of topics, resources and questions\n",
      "\n",
      "Purvanshi Mehta·Follow\n",
      "\n",
      "3 min read·Feb 15, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "8\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Interviewing is a grueling process, specially during COVID.\n",
      "\n",
      "I recently interviewed with Microsoft (Data Scientist ll), Amazon (Applied AI Scientist) and Apple (Software Development : Machine Learning).\n",
      "\n",
      "Though all these interviews differed a bit, but the basic questions asked were the same.\n",
      "###################\n",
      "During the process I curated this list which would help you pass all ML interviews.\n",
      "###################\n",
      "NOTE : This list is just for end moment revising\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "Linear, Logistic regression-http://cs229.stanford.edu/notes2020spring/cs229-notes1.pdf\n",
      "\n",
      "Naive Bayes- https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c\n",
      "\n",
      "SVM / Kernel- http://cs229.stanford.edu/notes2020fall/notes2020fall/cs229-notes3.pdf\n",
      "\n",
      "Random Forests, decision Trees, Boosting, Bagging, Xgboost- StatQuest Youtube videos https://www.youtube.com/watch?v=J4Wdy0Wc_xQ\n",
      "\n",
      "EM Algorithm- http://cs229.stanford.edu/notes2020spring/cs229-notes8.pdf\n",
      "\n",
      "K means-https://towardsdatascience.com/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1\n",
      "\n",
      "K nearest neighbors- https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/\n",
      "\n",
      "Evaluation Metrics (scroll to the definition section, you need to know the confusion metrics, precision, recall, type I, type II, FP rate, sensitivity)-https://en.wikipedia.org/wiki/Precision_and_recall\n",
      "\n",
      "Regularization (L1,L2, Why is L1 sparse?)\n",
      "###################\n",
      "https://explained.ai/regularization/L1vsL2.html\n",
      "\n",
      "Bias Variance Trade off\n",
      "\n",
      "Dimensionality Reduction-\n",
      "\n",
      "PCA deeplearning book chapter 2 (last pages) https://www.deeplearningbook.org/contents/linear_algebra.html\n",
      "\n",
      "TSNE https://distill.pub/2016/misread-tsne/\n",
      "\n",
      "Deep Learning\n",
      "\n",
      "The first thing I would suggest to do is to go through all the deeplearnig.ai courses which is pretty basic.\n",
      "###################\n",
      "If someone already publishes/ works in these topics they might just skip watching all the videos and can go through the following questions/ resources-\n",
      "\n",
      "Know what is- K fold cross validation, dropout, batch norm [Difference between batch norm and layer norm], early stopping\n",
      "\n",
      "Weight decay https://www.coursera.org/lecture/deep-neural-network/regularization-Srsrc\n",
      "\n",
      "Calibration https://arxiv.org/abs/1706.04599 (Look to what is calibration and ECE score)\n",
      "\n",
      "Transformer- The Illustrated Transformer — Jay Alammar — Visualizing machine learning one concept at a time.\n",
      "###################\n",
      "(jalammar.github.io)\n",
      "\n",
      "Attention (Multi head, single head) Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention) — Jay Alammar — Visualizing machine learning one concept at a time.\n",
      "###################\n",
      "(jalammar.github.io)\n",
      "\n",
      "Different Optimizers (Important are- Gradient descent, Adam, RMSprop, Adagrad, Adamax)- An overview of gradient descent optimization algorithms (ruder.io)\n",
      "\n",
      "Initialization- Initializing neural networks — deeplearning.ai\n",
      "\n",
      "NLP\n",
      "\n",
      "For NLP CS224 (5) Stanford CS224N: NLP with Deep Learning | Winter 2019 | Lecture 1 — Introduction and Word Vectors — YouTube) covers the basics of NLP with Deep Learning.\n",
      "\n",
      "This might cover 3/4 of the questions asked in an interview.\n",
      "###################\n",
      "Other questions are usually more state of the art models as the interviewer wants to check how updated you are.\n",
      "\n",
      "LSTM, GRU- Understanding LSTM Networks — colah’s blog\n",
      "\n",
      "BERT- A Visual Guide to Using BERT for the First Time — Jay Alammar — Visualizing machine learning one concept at a time.\n",
      "\n",
      "(jalammar.github.io) , GPT- GPT models explained.\n",
      "###################\n",
      "Open AI’s GPT-1,GPT-2,GPT-3 | Walmart Global Tech Blog (medium.com) and you can read the respective papers\n",
      "\n",
      "Different types of embeddings (Bag of words, TFIDF, Word2vec(skipgram[How is it trained], pre-trained (Google word2vec, Stanford Glove, fasttext, ELMo))).\n",
      "\n",
      "Need to know how incremental changes were brought into place.\n",
      "###################\n",
      "Other topics —\n",
      "\n",
      "Linear Algebra-https://www.deeplearningbook.org/contents/linear_algebra.html\n",
      "\n",
      "Probability basics- http://www2.ece.rochester.edu/~gmateosb/ECE440/Slides/block_2_probability_review_part_a.pdf\n",
      "\n",
      "Stats- I had taken a graduate level Statistics class so I didnt need to brush this up but Khan Academy https://www.khanacademy.org/math/statistics-probability is a very good source for learning basics with examples.\n",
      "###################\n",
      "These are the topics which are asked in all interviews, obvious then some questions were specific to research I had done.\n",
      "\n",
      "There were also live coding rounds both of algorithms and NN models.\n",
      "\n",
      "Let me know if I missed something.\n",
      "###################\n",
      "Canada’s Artificial Intelligence Ecosystem — Montreal\n",
      "\n",
      "Part 1: Montreal’s non-predatory model — how fellowship has fostered the world’s strongest AI research community\n",
      "\n",
      "Real Ventures·Follow\n",
      "\n",
      "Published inReal Ventures·8 min read·Apr 20, 2018\n",
      "\n",
      "ListenShare\n",
      "\n",
      "2\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Written by Laura Easton, edited by Lauren Jane Heller\n",
      "\n",
      "This is the first of a series of posts aimed to provide an insider perspective on all aspects of Canada’s AI ecosystem, with a particular focus on Montreal and Toronto — two of Canada’s most active AI cities.\n",
      "###################\n",
      "Johnny Chen on\n",
      "\n",
      "Unsplash\n",
      "\n",
      "There’s no question that Canadian AI is booming.\n",
      "\n",
      "But what makes the Canadian major cities such exceptional hubs of research and startup activity?\n",
      "###################\n",
      "After digging into the history of key AI actors and institutes in Montreal, the relationships among them and their impact on local entrepreneurs and the growth of the community, we found that Montreal’s AI story has three parts, all of which have positive network effects for startups and corporations working in AI:\n",
      "\n",
      "Research roots and a collaborative model\n",
      "\n",
      "An AI research network that has drawn global interest and talent\n",
      "\n",
      "Local and global supporters\n",
      "\n",
      "Montreal’s non-predatory model\n",
      "\n",
      "The major difference between Montreal and many other technology hubs is the atmosphere of fellowship and the belief that scientific progress should be for everyone.\n",
      "###################\n",
      "This foundation of knowledge sharing — forged by some of the most prominent AI researchers in the world — has led to to a convergence of AI talent and research support, as well as the establishment of AI research labs, both academic and corporate, in the city.\n",
      "\n",
      "Montreal is rooted in its research\n",
      "\n",
      "La Belle Ville has research roots that extend across the globe.\n",
      "###################\n",
      "Many top AI researchers have engaged with academic programs in the city and some, including Hugo Larochelle of Google Brain, have left and then returned to Montreal to grow privately-funded AI labs.\n",
      "\n",
      "With corporations anxiously recruiting the less than 22,000 people in the world who have the skill-set to tackle tough AI problems—often through astronomic salaries —there is now an even greater need for top researchers to train next generation talent.\n",
      "###################\n",
      "This is Montreal’s strength, thanks to a conglomerate of great minds brought together by Yoshua Bengio.\n",
      "\n",
      "Professor Bengio is a Canadian computer scientist, AI pioneer, and part of the “Deep Learning Conspiracy.” Decades ago, when deep learning theories about neural network operations failed to meet practical applications, financial support froze and the research fell into an AI winter.\n",
      "###################\n",
      "While most researchers waited for computing power and data to ramp-up, computer scientists, Geoffrey Hinton, Yann LeCun and Yoshua Bengio, kept the fire going.\n",
      "\n",
      "As data became the new currency and AI scaled, Hinton and LeCun were recruited to work with Google and Facebook, respectively.\n",
      "\n",
      "Yoshua Bengio, however, remained committed to academia and the training of the next generation of senior experts in deep learning.\n",
      "###################\n",
      "The non-predatory model his team created at the Montreal’s Institute for Learning Algorithms (MILA) and more recently through the co-founding of Element AI, is keeping major research talent in universities rather than siloed in big corporations, all the while facilitating the commercialization of AI knowledge via collaboration with startups and enterprises.\n",
      "###################\n",
      "Bengio’s dedication to research through his investment in developing programs at Université de Montréal, MILA, through Element AI, and other research institutes, has also shone a bright light on Montreal’s AI Ecosystem and led to a significant number of prominent tech companies establishing their AI presence in Montreal.\n",
      "###################\n",
      "Montreal’s magnetic AI research network\n",
      "\n",
      "While Bengio may be Montreal’s AI pioneer, it’s the research institutes and critical mass of AI intelligence workers that have drawn in the interest of corporations and startups looking to harness this cutting-edge technology.\n",
      "###################\n",
      "In 2016, machine learning researchers, largely from Université de Montréal and McGill University, established Montreal’s Institute for Learning Algorithms (MILA), an institute that facilitates and democratizes access to talent and research for applied AI in the business sector.\n",
      "\n",
      "MILA attracts top post-doctoral and PhD talent from all over the world and is building the next generation of AI researchers.\n",
      "###################\n",
      "Organizations can gain access to technical and business advisory services related to R&D — including those provided by MILA — through the Canadian National Research Council’s Industrial Research Assistant Program (IRAP), which is committed to helping Canadian firms build competitive advantages.\n",
      "###################\n",
      "MILA’s expertise and programs are complemented by other publicly and privately-funded institutes:\n",
      "\n",
      "The Computer Research Institute of Montreal (CRIM) has served Quebec enterprises by acting as a bridge between university research and business needs since 1985 and has collaborated on AI projects for nearly 30 years.\n",
      "\n",
      "Researchers at CRIM execute projects similar to MILA but on a smaller scale.\n",
      "###################\n",
      "Entrepreneurs and enterprises can access CRIM resources through a membership model, which opens up a large network of IT companies, as well as subject-matter expertise and innovation partnerships.\n",
      "\n",
      "IVADO, Montreal’s Institute for Data Valorization, fills the supply/demand gap faced by CRIM and MILA by democratizing and raising awareness of machine learning and operations knowledge through membership programs.\n",
      "###################\n",
      "Since 2015, this partnership between Université de Montréal, HEC Montréal and Polytechnique Montréal has curated an innovation network of more than seventy partners including major Montreal players in transportation, energy, commerce and healthcare.\n",
      "\n",
      "As members of IVADO, entrepreneurs and enterprises join a platform for knowledge exchange and collaboration between the specialists, partners, researchers and students in its network.\n",
      "###################\n",
      "In the past two years, there has also been a major influx of privately-funded AI research labs to Montreal, driven by the convergence of talent and proximity to key resources for information exchange and collaboration.\n",
      "\n",
      "This concentration of expertise helps reinforce developments in AI applications and grow new AI-focused businesses.\n",
      "\n",
      "Among the most notable are:\n",
      "\n",
      "Element AI, co-founded in 2016 by Jean-Francois Gagne and Yoshua Bengio.\n",
      "###################\n",
      "The team has quickly grown to 300 employees over the past two years and is the largest privately-owned Canadian AI R&D lab.\n",
      "\n",
      "Microsoft acquired Montreal AI lab, Maluuba, in early 2017 with plans to double technical experts to 75 over the next two years.\n",
      "\n",
      "Samsung Electronics’ Advanced Institute of Technology (SAIT) opened an AI lab in the Université de Montréal in August 2017.\n",
      "###################\n",
      "SAIT has been collaborating with Bengio and other partners from the University of Toronto, McGill University and NYU since 2014.\n",
      "\n",
      "Google Brain recruited former student of Bengio and Montreal native, Hugo Larochelle, in mid-2017, to run their AI research in Montreal.\n",
      "\n",
      "Facebook established FAIR Montreal in late 2017 and hired Joelle Pineau (a McGill University Professor of Computer Science) to head this lab.\n",
      "\n",
      "FAIR is hiring 10 researchers initially and plans to triple in size by the end of 2018.\n",
      "###################\n",
      "DeepMind, acquired by Google in 2014, announced the opening of a research lab in Oct 2017 headed by Doina Precup (McGill University Professor of Computer Science).\n",
      "\n",
      "Thales SA, announced plans to open a lab in Montreal in October 2017.\n",
      "\n",
      "They are currently members of IVADO and plan to partner with MILA.\n",
      "\n",
      "By mid-2019, they hope to expand to 50 AI scientists.\n",
      "\n",
      "The Royal Bank of Canada will open a Borealis AI lab in 2018.\n",
      "\n",
      "They aim to have ten researchers on staff in the first year.\n",
      "###################\n",
      "These corporations were drawn to Montreal by the expertise of the city’s researchers, yet many of the labs are being led by academics like Bengio, Precup and Pineau, who will continue to teach at their respective universities, while overseeing the application of their research for business purposes.\n",
      "###################\n",
      "Further, because of the prominence of these researchers — and importance of their labs’ developments — there has been a major injection of financial support into university research centres by both government and multinational players.\n",
      "\n",
      "Major support for a flourishing AI ecosystem\n",
      "\n",
      "The Canadian and Quebec governments, as well as international corporations, are playing a crucial role in both funding Montreal research organizations and in the recruitment and retention of talent in Canada.\n",
      "###################\n",
      "There is no question that global AI leadership is a national priority.\n",
      "\n",
      "In the past two years, Quebec has received significant funding that has enabled the province to reinforce and build infrastructure to better serve local AI initiatives and attract and retain AI researchers, entrepreneurs and research labs.\n",
      "\n",
      "This support comes from two major sources: government (federal, provincial and municipal) and multinational (corporate and philanthropic) funds.\n",
      "###################\n",
      "Government support:\n",
      "\n",
      "In September 2016, the Canada First Research Excellence Fund allocated:\n",
      "\n",
      "$84 million to McGill University for their Healthy Brains for Healthy Lives (HBHL) initiative\n",
      "\n",
      "$93.5 million to Université de Montréal for Optimization of Deep Learning and Knowledge sharing (IVADO)\n",
      "\n",
      "In March 2017, $40 million was allocated to Montreal from the Government of Canada’s $125M Pan-Canadian AI Strategy, administered by the Canadian Institute for Advanced Research (CIFAR).\n",
      "###################\n",
      "In spring 2017, $100 million was allocated by the Government of Quebec for the creation of a provincial wide cluster and institute for Artificial Intelligence.\n",
      "###################\n",
      "In March 2018, the Government of Quebec communicated the grant of:\n",
      "\n",
      "$5 million toward the establishment of an international organization on artificial intelligence\n",
      "\n",
      "$10 million toward NEXT.AI and CDL, initiatives of HEC Montreal, over the next five years\n",
      "\n",
      "Corporate and Multinational funds:\n",
      "\n",
      "In 2016, Google announced it would give $3.33 million USD over three years to the MILA\n",
      "\n",
      "In early 2017: Microsoft contributed $7 million USD to McGill University and Université de Montréal AI Labs\n",
      "\n",
      "In August 2017: MILA was awarded $2.4 million USD research grant from the US-based Open Philanthropy Project, to make AI safer for society\n",
      "\n",
      "As this financial support has rolled in, the City of Montreal is working hard to build infrastructure to serve local AI startups and research labs, with Montreal International, the city’s economic development agency for foreign investment leading efforts to attract more AI talent and corporate investment, and Montreal’s Chambre de Commerce (CCMM) driving thought leadership and local engagement via Quebec’s biggest AI forum of the year.\n",
      "###################\n",
      "Montreal’s critical mass in AI: a win for the ecosystem\n",
      "\n",
      "The investment into AI research and infrastructure is fuelling the AI fire in Montreal.\n",
      "\n",
      "For major corporations, this means access to a much larger pool of talent and the latest cutting edge research.\n",
      "\n",
      "For startups building AI-first companies, the cost of living and quality of life in Montreal means that more researchers will be interested in joining teams that can’t pay astronomical salaries (yet!\n",
      "###################\n",
      "), and they can also benefit from the latest cutting-edge research through MILA, IVADO and the other institutes.\n",
      "\n",
      "As Montreal’s talent attracts international attention and investment in Montreal labs, more AI talent is drawn to the city and facilitates knowledge sharing of AI developments.\n",
      "\n",
      "This positive feedback loop of talent attracting talent and developments driving knowledge sharing, has and will continue to drive growth in Montreal’s thriving AI ecosystem.\n",
      "###################\n",
      "All of this together paints a clear picture: Montreal is a city to watch, or move to, for those interested or working in cutting-edge artificial intelligence.\n",
      "\n",
      "The open nature and organic fellowship that defines Montreal’s entrepreneurial communities are proof that the city’s non-predatorial model works.\n",
      "\n",
      "The AI community goes further together, rather than faster alone.\n",
      "\n",
      "2018 Snapshot\n",
      "\n",
      "Techstars.AI and NEXT AI Accelerators.\n",
      "###################\n",
      "As content develops in this series, this map will become more granular, highlighting relationships and linking to definitions and resources as appropriate.\n",
      "\n",
      "In next posts in this series, we will dive into the Toronto AI ecosystem and then zoom out to look at the broader Canadian AI landscape, what startups are doing and how Canada’s major AI hubs compare internationally.\n",
      "\n",
      "Follow us for these and other in-depth articles!\n",
      "###################\n",
      "Member-only story\n",
      "\n",
      "Artificial Intelligence\n",
      "\n",
      "OpenAI Brings Introspection to Reinforcement Learning Agents\n",
      "\n",
      "The research around Evolved Policy Gradients attempts to recreate introspection in reinforcement learning models.\n",
      "###################\n",
      "Jesus Rodriguez·Follow\n",
      "\n",
      "Published inTowards AI·4 min read·Apr 12, 2021\n",
      "\n",
      "ListenShare\n",
      "\n",
      "-\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "https://janzz.technology/the-rise-of-the-machines-cognitive-computing-disruptive-potential/\n",
      "\n",
      "I recently started an AI-focused educational newsletter, that already has over 80,000 subscribers.\n",
      "\n",
      "TheSequence is a no-BS (meaning no hype, no news etc) ML-oriented newsletter that takes 5 minutes to read.\n",
      "\n",
      "The goal is to keep you up to date with machine learning projects, research papers and concepts.\n",
      "###################\n",
      "Please give it a try by subscribing below:\n",
      "\n",
      "TheSequenceSubscribe to stay up-to-date with the most relevant projects and research papers in the AI world.\n",
      "\n",
      "Trusted by 85,000+…thesequence.substack.com\n",
      "\n",
      "Introspection is one of those magical cognitive abilities that differentiate humans from other species.\n",
      "\n",
      "Conceptually, introspection can be defined as the ability to examine conscious thoughts and feelings.\n",
      "\n",
      "Introspection also plays a pivotal role in how humans learn.\n",
      "###################\n",
      "Have you ever tried to self-learn a new skill such as learning a new language?\n",
      "\n",
      "Even without any external feedback, you can quickly assess whether you are making progress on aspects such as vocabulary or pronunciation.\n",
      "\n",
      "Wouldn’t it be great if we could apply some of the principles of introspection to artificial intelligence(AI) discplines such as reinforcement learning (RL)?\n",
      "###################\n",
      "The magic of introspection comes from the fact that humans have access to very well shaped internal reward functions, derived from prior experience on other tasks, and through the course of biological evolution.\n",
      "\n",
      "That model highly contrasts with RL agents that are fundamentally coded to start from scratch on any learning task relying mainly on external feedback.\n",
      "\n",
      "Not surprisingly, most RL models take substantially more time than humans to learn similar tasks.\n",
      "###################\n",
      "Recently, researchers from OpenAI published a new paper that proposes a method to address this challenge by creating RL models that know what it means to make progress on a new task, by having experienced making progress on similar tasks in the past.\n",
      "\n",
      "Titled Evolved Policy Gradients(EPG), the OpenAI research paper introduces new meta-learning technique based on the concept of a loss function that qualifies the learning progress.\n",
      "###################\n",
      "When used in RL models, the EPG method does not encode the knowledge explicitly through memorized behaviors but, instead, it uses an implicitly mechanism through a learned loss function.\n",
      "\n",
      "The EPG end goal is that RL agents that can use this loss function to learn a novel task.\n",
      "\n",
      "Algorithmically, EPG consists of two optimization loops.\n",
      "\n",
      "In the inner loop, an agent learns, from scratch, to solve a particular task sampled from a family of tasks.\n",
      "###################\n",
      "The family of tasks might be “move gripper to target location [x, y]” and one particular task in this family could be “move gripper to position [50, 100]“.\n",
      "\n",
      "The inner loop uses stochastic gradient descent (SGD) to optimize the agent’s policy against a loss function proposed by the outer loop.\n",
      "###################\n",
      "The outer loop evaluates the returns achieved after inner-loop learning and adjusts the parameters of the loss function, using Evolution Strategies (ES), to propose a new loss that will lead to higher returns.\n",
      "\n",
      "From the metalearning standpoint, the loss function consists of temporal convolutions over the agent’s recent history which can lead to interesting side benefits.\n",
      "\n",
      "For instance, by examining the agent’s history, the loss could incentivize desirable extended behaviors, such as exploration.\n",
      "###################\n",
      "Further, the loss could perform a form of system identification, inferring environment parameters and adapting how it guides the agent as a function of these parameters (e.g., by adjusting the effective learning rate of the agent).\n",
      "\n",
      "Metalearning policies is nothing new in the RL field but the EPG techniques does bring some very tangible benefits compared to traditional approaches.\n",
      "###################\n",
      "One of the most obvious advantages of the EPG method is that it avoids the local-minima Achilles’ heel of RL models.\n",
      "\n",
      "Since RL methods optimize for short-term returns instead of accounting for the complete learning process, they may get stuck in local minima and fail to explore the full search space.\n",
      "\n",
      "The EPG method allows RL models to optimize for the true objective, namely the final trained policy performance, rather than short-term returns.\n",
      "###################\n",
      "In initial tests, EPG seems to improves on standard RL algorithms by allowing the loss function to be adaptive to the environment and agent history, leading to faster learning and the potential for learning without external rewards.\n",
      "###################\n",
      "Among the interesting tests conducted by the OpenAI researchers in order to test the generalization ability of EPG, there was an experiment focused on using the EPG loss to be effective at getting “ants” to walk to randomly located targets on the right half of an arena.\n",
      "\n",
      "After an initial calculation of the loss function, the experiment gave the ants a new target, this time on the left half of the arena.\n",
      "\n",
      "Surprisingly, the ants learned to walk to the left!\n",
      "###################\n",
      "Here is how their learning curves looked (red lines on graph.\n",
      "\n",
      "The type of knowledge generalization achieved by EPG models is very encouraging compared to traditional metalearning models because is doesn’t rely on the training distribution.\n",
      "\n",
      "The OpenAI team complemented the research paper with an initial implementation of EPG available on Github.\n",
      "\n",
      "The EPG implementation is based on the Python and Anaconda which should make it relatively simple to use with other deep learning frameworks.\n"
     ]
    }
   ],
   "source": [
    "web_content_splits = split_into_chunks(web_content, chunk_size=500)\n",
    "print('\\n###################\\n'.join([page.page_content for page in web_content_splits]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:30:38.253615463Z",
     "start_time": "2023-06-03T10:30:38.174129370Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Upserted vectors:   0%|          | 0/197 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ba793263dda4a6594d137c16931567d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "['f4790a55-879c-462d-a137-85b85ac04789',\n '5727503b-f1bb-465c-9967-7464e015ca49',\n '1b74b30c-bd3b-4f6a-afa3-a514f2b2f30e',\n '9d6fdcad-4d38-42d1-b3e4-52e6d5d6c3e5',\n '4ec996dd-1e65-43a2-b95f-3e30619d761f',\n '2c24b78a-2fb0-4eeb-bdac-fe3c74f85ddf',\n '13fe219f-c12d-4622-b50d-136d671c33ee',\n 'afa5219d-eadc-4b08-ac93-6f4af099b6f9',\n 'd8464343-4a73-4f21-bcd6-0283983820a8',\n '8964a7a9-6b76-44c5-813f-c32f3b93d465',\n 'a21d6693-d6bc-4bc4-b588-2fb7b324865a',\n 'e4ab41f0-b4cf-4c44-af6f-2ed2686aba2f',\n '6825b24f-a9bf-4d30-ab37-e93c6c6707e1',\n 'c12051ff-1e4a-4e48-ae39-6cb44a802ec5',\n '8a9cb8f9-8055-4c40-94db-c7a66b3c39d9',\n '37d54c68-83d9-4624-9c5d-de4743d27802',\n '78df2c34-83e4-4d1b-b8ce-8d02965cbf4c',\n 'c3ad5668-9c6f-48bf-a535-c9e051fac221',\n '04c6fe59-6d91-42ed-b72b-06fbaf37546c',\n 'b0fb57ac-a8be-4d98-aeb5-7b62a6a2a979',\n 'f5f7a0ae-06ed-415b-89ee-67cd780d4573',\n '49a00ed5-c070-4ecd-b683-4c5d4976cebe',\n 'f8709944-c8bb-4f52-ba95-8844cb923baf',\n '565e795b-b7fc-4f48-9e7b-5e65347b472b',\n 'd9efab0f-1038-400e-9b71-5c678f95560d',\n 'fffcbddc-a2f3-4e37-8aac-129e400ca227',\n 'e820cdff-e9aa-49d1-ba46-b5e38f99527a',\n 'ef4b12e2-b325-4d3a-90b4-85e766bb15d4',\n '2d94e179-629d-4796-9d6c-1cc9e607c48b',\n '81ff4f49-39c9-4437-838b-1bb62bc2c35b',\n '1117ef7d-5da2-4329-8174-e61f097ba8c5',\n 'a73b88fc-9f27-4722-9712-7d66c2af11d0',\n '8ae484c6-529d-44a0-ad84-5aee5682a258',\n 'a33a69d9-85c0-4a06-a8a9-2d8798b4c148',\n 'bb730ad7-b35c-4726-a612-160a2fdf837b',\n '838158a2-56b5-4af8-b4a1-258be819f668',\n '6eb3d165-a279-4940-aec8-e46a4e1c0315',\n '14459784-d663-4d8c-98b5-c43fa0da8fc7',\n '567efe43-c7eb-47c5-a7b9-a25580490d95',\n 'f920aea4-fd94-4457-8ed1-af5983d1901a',\n 'cc42a87f-64d9-4554-9e09-2b3972faba3a',\n 'abd079c7-a7d7-46f9-a6ab-28d552fb79fc',\n '8c0e2f2e-7fa0-4f0a-8e91-b3b1f25812fd',\n 'd98f74f6-745f-46d3-a6ee-dbe89287f8fc',\n 'ed929c03-6711-4fc5-9d0e-c0e9d89f134f',\n '26e4a944-1c2a-4afe-b875-bafcf9d263cf',\n '379f2cef-a14c-4fff-b80d-d9955431056c',\n '03f02593-1434-4a58-ab6a-7570da6917fa',\n '1d401c1e-48ac-4dc4-8033-6875329e8fe8',\n 'f3b1c2d1-1816-4335-81ba-6bcf7eb395c0',\n 'b1ae54c7-4f77-4738-bbc1-a9e521bb39c2',\n 'a6632a4e-1b5a-4c05-94d0-8366def8be82',\n 'b78d8bf3-0d77-465f-9ed4-20a8ed4dd0b7',\n 'db75ed28-8292-4c76-a612-52d1de68b1fc',\n '80bd1084-1ef2-4cae-b38e-c367fac68d2c',\n 'f29eacc8-7159-459f-8f70-c7fdc915e433',\n '818d7d3b-4eb4-45ad-9208-427fdd04394b',\n '8504972e-8409-4283-b56a-a47d1518f037',\n 'e746467e-a730-411f-8eaf-beccb303f24e',\n 'dd2b662c-c162-4dec-b1c4-276d158ad350',\n 'a913c214-a8cb-428a-b4cd-d5ebfd68f121',\n 'ab664ee4-3b99-461f-9d54-2db685e75eee',\n '21d7e78c-ff23-40fa-a7b6-e1b0280648c6',\n '42d1b8bf-5405-488c-b2d1-767267ce0157',\n '4d44a546-846b-47a8-8319-4b3c3f8491d3',\n '0b5a99d9-8376-4cce-8b9b-e89b9d55fcd5',\n 'f9d9d279-bb01-4bf9-a250-1f8e2b18da19',\n '8b5d73cb-21c6-4e53-a032-21fa32476324',\n '767942b5-c474-41cc-8934-04c000769d92',\n 'd6f75490-6820-4690-b869-e2d0deb05109',\n 'ed751c7c-1dfa-49f3-ac0b-c80068eb831a',\n '2e41c5d6-2f8f-44b9-adfc-777670a111eb',\n '31b33f05-969e-4296-9dd3-57fda3410dc6',\n '70e5e146-5268-4124-a1fe-743937fdcee3',\n '16d6105e-8925-49b9-be03-f792d7ddf032',\n 'ff8f4f61-96e4-44ed-a961-4379d399d299',\n '91702cb6-3add-4744-a47e-02043649870c',\n 'f25d377e-ae65-4bed-987c-5df1517519e5',\n 'aa5122e1-416b-4a6d-97a2-ea429ed6bfa3',\n 'b06a6d9b-27a0-4cb8-a63c-fdb60127a1bc',\n 'e03184f1-8fce-4ca2-a1c6-29a205756290',\n 'ab621f5e-8b0a-4542-86ec-e5e513886bbc',\n '18f770a0-1fe6-4e3e-9da1-b0249c5bc974',\n 'fc45a263-c73d-4429-980b-6da0874cde59',\n '7a5f3672-373f-477e-a794-0ee4c2079870',\n '54732583-59c3-47ed-83f8-395a1e397dac',\n '4c72bbc2-59c7-452a-929f-83a3a99d8449',\n 'e745a3d9-bd41-4fe0-879a-ec31bbe5b2f9',\n '11057a95-9c6e-476a-a6dc-5091fd8536bc',\n '0d18f3ee-19be-4868-aa5e-fcfbcadac11d',\n '1f60225b-8fa0-4dcd-8714-8c2dc9c2dbe6',\n 'cbfe4edf-9203-4d74-a398-c28165c3fb3d',\n '4821764d-b1b6-4962-8613-efb8b965bed8',\n '9dfa4554-2e61-41cb-9a41-bfdf05480698',\n '9e3a5212-02f3-40ce-9177-8b98eb467045',\n '06e8a4a0-3d1f-4148-aab3-4d9fd5069a8a',\n 'e1acb3a9-4390-4bce-80e9-78e2f3e25a20',\n '7bc0cb15-648f-485c-893a-4e7d5eddecd4',\n '1a9d97be-d825-4b2a-868f-734600c3701f',\n '63cb192e-7aff-45f1-b5da-aa2a253e0d22',\n '23c2963b-64d2-4fa4-8e55-8921e5eabfbf',\n 'fdf01152-8195-4af1-a54f-d8263c2de3cf',\n '71e0ef6b-27df-493e-806d-20776e88e4ee',\n '9bf9d2b4-edd9-4f5a-8142-5cbf83adee59',\n '084a0c4c-13cd-4df9-b6fd-ec9d915709b0',\n '832c4ed5-93d3-4984-a551-bd8b30bb5a52',\n 'f9acbb70-dfe0-419b-81fd-45619b8833db',\n 'c636832f-4da0-4213-a578-3958ee79d3b6',\n '493f9df7-d825-43e4-bb84-c57a30a529de',\n '9b053122-213d-4b0f-ba92-e140dcc9f544',\n '6699cc34-6982-458c-9617-e5769dd4133c',\n 'af4aab4a-1fe8-482c-8400-0e1c5d5f9508',\n '39a432fa-f5a6-4549-92e1-9436ba79d5bd',\n '2e50192d-5956-416f-b387-0051c0f6ac6d',\n '28328595-d72c-4b4c-bb8d-0f06fbf24c94',\n '6332cefc-a121-4216-9699-375657ceee72',\n '7b48b0d4-2e37-4167-b7b3-3d9640a7cda6',\n '7fed1ed4-8de9-447d-9380-21f13c4ec6fd',\n '28db3161-16b7-41ce-822d-ebad65f72925',\n '9a22e867-e69f-4a9d-8e28-38af099cc744',\n '7fc05c77-b545-4de4-92c2-9514a10614c7',\n '7a571bdb-11a1-4fc5-ad1c-ab07bb6c9a90',\n '84e2a694-46da-4952-a601-216b0918dbd6',\n '2bb2695b-da70-44d9-9b6d-07bec4fb8b08',\n '7495f3cb-2952-44f3-9797-08a0920ac26b',\n 'fe738fd0-0945-4b07-a028-153fedfc7449',\n '047d257b-d4e7-440b-87b0-5d3c0bf42d04',\n '86144c4a-8550-4835-8d8d-9e434bd24f19',\n 'f9418fc6-9638-47d1-bf49-f31dc91e77f5',\n 'ecf1738b-1836-4b28-8a89-3c1d93040e54',\n 'b190e467-74e6-440d-8c61-6b14795b3678',\n '6797d6e9-158a-4670-b7cb-1bfddcf8d7ed',\n '81164b64-bcdf-4c19-9663-094e853d52b6',\n 'cc88ae24-4aa0-4f9c-b944-e0753282c82a',\n '9945062d-4645-47fc-aa10-d0b8d00b6f68',\n 'f33f4384-b0da-4098-b510-cb9db84e1fa2',\n '68cc54ab-a7b9-4404-a1bf-40ddefb64b99',\n '33a2fb77-3ec9-40ac-abed-d502e9057397',\n 'c431abe3-ea49-446c-8390-b6c6dc6a83e9',\n 'a76cd8fa-81ea-4425-a63f-78f924dd9651',\n 'bbe152fb-3b93-4f2d-b4c8-07eaaacbc513',\n '29d9c05c-ca88-4fee-aa36-7e8a0cc0a13d',\n '6b6cfc41-42fa-414e-bdf9-34bd69ee9ca4',\n 'ad61a1cb-13a0-4116-a887-4d39d0960113',\n '61972d79-f0cb-4ddd-ae79-092b5d478869',\n '0b0ffb05-d807-431a-bbe2-22c1941116d7',\n 'aa0e8a0d-4e00-4168-9343-14593dff8cd4',\n 'da79043c-b380-4b03-a703-6709f0c4dceb',\n '0db020df-b21f-4d56-a404-9ba83cd752c0',\n 'e0e26c6c-27dd-4853-89e3-60aeb149ec85',\n '5d51791b-6ad7-444e-bf19-5813c10ef8da',\n '3ad175f3-2bdf-405a-aaee-3dbb827c7722',\n 'fd98aa11-c793-41f3-b7bf-4d12ed1bb3eb',\n 'b6fbf85d-5e34-480c-b91e-96c7b0ba9ce0',\n '176ff6e8-f006-4f4d-a9c8-a9ceab77e09a',\n '328fa8d1-456b-4ff6-863a-96e577d6cec5',\n 'ca0547ee-641e-49ab-b5db-88dcc81c8895',\n '8a142fb0-c539-4f6b-bc36-b8732b051e0c',\n 'ba703a8f-4b46-40c0-83c6-cfe679a26f87',\n '3a92f993-b09c-468f-8e32-a9a5b5f26bc0',\n 'cfcde8ce-c991-4806-a44e-5771a05ce17f',\n '7d8dab72-9081-4441-b836-744431f4d400',\n '403447aa-d323-4f39-a843-86b280efb722',\n '913b0fd7-a48b-4c1d-a69e-440e8ca510e1',\n 'c960706a-790b-40e1-9989-e592ece2a40a',\n '6bf28f8f-da99-4427-8e4b-172751f217bc',\n 'e233b9a1-123a-4316-a34e-5cdc46470b75',\n '5b5b54c9-a056-4532-9f8b-f8fb2d304ae2',\n '9052e68d-99f1-4409-808f-ccbc66c80522',\n 'eec48f17-23db-402e-bb24-a0520b71b43f',\n 'a7844c11-2534-4281-a983-aaf4271ffd5d',\n '9f967e23-0cd9-486e-aa6d-aad416893d8e',\n '73a1f273-b3c4-47ef-8eab-3dd0f3de8733',\n 'efebf7f2-816e-4cd0-981a-3f67b4accaa9',\n '4cfd21c5-8500-4f28-a297-872a883e3921',\n '2855d3b2-c378-45db-bff0-32a82224aaa3',\n 'a07ffc1b-dbec-462b-95fd-5a77542fd46c',\n 'f0474d03-317e-4170-8d85-0c5ab1cb4146',\n 'c281112b-58c6-48c2-9dae-e0d2ba105a4d',\n 'e0b7211c-d736-448c-b2aa-bc381f5e97a6',\n '2ca5d339-ed92-4d80-9a5e-b795282fbfb4',\n '6c130513-50df-4b2b-8739-d5cac9615564',\n 'eaeaa022-c905-4507-9c95-92d5be2b9e36',\n '94f09b5b-52fb-4c04-9511-6e114ae8976b',\n '4cb7f9b5-c6c9-42af-af33-f494a778c04b',\n '36a4c37d-ecfc-4cc1-bcdd-b5574761e73c',\n '9d6c0411-06f2-4672-8613-205686c72d7f',\n '1ba74559-85cc-4fe0-891e-80d8ae8668f5',\n '2ff7bc9c-c32b-4ebf-acfa-235c2e52f8ee',\n '620301f3-98ac-49f0-bfda-d9e2951b8327',\n 'fe91e637-1ffd-4d37-84c0-5588ccb72926',\n '82c136c7-2983-422e-b9c6-b82ca180913b',\n '49e79e14-70de-4418-93ab-c5aa7079f263',\n '02b1ad60-9eba-4178-8979-b8223fcd8dea',\n '6fc7f242-7462-438a-a96d-b350a10bff15',\n '70e3445f-3cc8-45c6-924a-51cf6de34f01',\n '42df60f6-fb84-4908-af4d-5a8071ed7a45']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore_controller.add_documents_to_vectorstore(web_content_splits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T10:33:47.200756618Z",
     "start_time": "2023-06-03T10:33:33.409596427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-03T10:34:38.136730308Z",
     "start_time": "2023-06-03T10:34:37.862011113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Non-functional requirements: Specify all properties, abilities, conditions, and behaviors of the system that are \\nnot associated with a functionality\\nExamples: Performance, energy consumption, privacy, safety, security, reliability, development cost\\nConstraints: Specify restrictions on the implementation of the system\\nExamples: Must run on system X; must deliver a result in X seconds; must finish dev in 180 days\\n6', metadata={'page': 5.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='Architecture Characteristics / Non-Functional Requirements\\n\\nBriefly, functional requirements define what a system is supposed to do, like in the case of a car, take a person from A to B, and non-functional requirements stipulate how a system is supposed to be.\\n\\nHere is the overall cheatsheet of NFR:\\n\\nhttps://imgur.com/a/HzPp8s0\\n\\nThese top 10 Architectural Characteristics covers most of the aspect of a large-scale project.', metadata={'source': 'https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------'}), Document(page_content='Types of Requirements\\nFunctional requirements: Specify function (features) of a system\\nExamples: Interface to a payment system, email notification, order system, logistics, management, etc.', metadata={'page': 5.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='Non-functional / quality requirements: Define requirements on quality attributes (explainability, legal req.)\\n\\nHardware requirements: Specify the HW systems the AI component trains and inferences on.', metadata={'page': 14.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='omitted, vague \\nrequirements, volatile, conflicting views\\nTranslate vague requirements into actionable (conflict -free),\\nunambiguous specifications that can later be tested or verified\\nUse case diagrams, formal requirements specifications, user stories\\nChallenges: Multitude of vague with different scales and dimensions,\\nconflicting requirements, concretizing requirements, verifiable \\nmetrics, capturing of pre -/post- conditions \\nValidate the specification with customers (see problems for elicitation)\\nFind appropriate forms for validation (prototypes, mockups, etc.)', metadata={'page': 6.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='Member-only story\\n\\nTop 10 Architecture Characteristics / Non-Functional Requirements with Cheatsheet\\n\\nLove Sharma·Follow\\n\\nPublished inDev Genius·7 min read·Jun 30, 2022\\n\\nListenShare\\n\\n14\\n\\n-\\n\\n14\\n\\nListen\\n\\nShare\\n\\nImagine you are buying a car.\\n\\nWhat essential features do you need in it?\\n\\nA vehicle should deliver a person from point A to point B.\\n\\nBut what we also check in it is Safety, Comfort, Maintainability, Ease of repair or Better mileage.', metadata={'source': 'https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------'}), Document(page_content='Challenges:\\n- Customers not knowing or able to describe what they want\\n- Different languages, conflicting requirements, evolution\\nTypes and techniques:\\n- Functional requirements, elicited via scenarios, walkthroughs, use cases\\n- Non-functional / quality requirements, elicited via stakeholder survey\\nDo never assume that you know what the customer wants!', metadata={'page': 4.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='Requirements Specification\\nTurning diverse, ambiguous requirements to concrete, actionable, unambiguous specifications that a \\nsoftware engineer can understand (and implement).', metadata={'page': 9.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='Examples: General Data Protection Regulation (GDPR) constraints that personal data can only be used in ways specified \\nby an explicit consent.In essence: We would need to know what the ML model delivers before we developing it.', metadata={'page': 26.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}), Document(page_content='You may also look for an electric version or better speed.\\n\\nWhy?\\n\\nTo limit the surprises which may occur in delivering the primary function, i.e., take a person from Point A to Point B.\\n\\nSimilarly, just like a car, motorcycle, or House, the software has its non-functional requirements called “Architectural Characteristics”.\\n\\nBe it a website, a mobile or a desktop app; it should have a set of quality attributes to meet end-user needs.', metadata={'source': 'https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------'})]\n"
     ]
    }
   ],
   "source": [
    "# similarity search\n",
    "query_results = vectorstore_controller.query_vectorstore(\n",
    "    query=\"What is an example for a non-functional requirement?\", k=10, get_raw_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-03T10:34:39.070288060Z",
     "start_time": "2023-06-03T10:34:39.021624371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page content: Non-functional requirements: Specify all properties, abilities, conditions, and behaviors of the system that are \n",
      "not associated with a functionality\n",
      "Examples: Performance, energy consumption, privacy, safety, security, reliability, development cost\n",
      "Constraints: Specify restrictions on the implementation of the system\n",
      "Examples: Must run on system X; must deliver a result in X seconds; must finish dev in 180 days\n",
      "6\n",
      "metadata: {'page': 5.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Architecture Characteristics / Non-Functional Requirements\n",
      "\n",
      "Briefly, functional requirements define what a system is supposed to do, like in the case of a car, take a person from A to B, and non-functional requirements stipulate how a system is supposed to be.\n",
      "\n",
      "Here is the overall cheatsheet of NFR:\n",
      "\n",
      "https://imgur.com/a/HzPp8s0\n",
      "\n",
      "These top 10 Architectural Characteristics covers most of the aspect of a large-scale project.\n",
      "metadata: {'source': 'https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Types of Requirements\n",
      "Functional requirements: Specify function (features) of a system\n",
      "Examples: Interface to a payment system, email notification, order system, logistics, management, etc.\n",
      "metadata: {'page': 5.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Non-functional / quality requirements: Define requirements on quality attributes (explainability, legal req.)\n",
      "\n",
      "Hardware requirements: Specify the HW systems the AI component trains and inferences on.\n",
      "metadata: {'page': 14.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: omitted, vague \n",
      "requirements, volatile, conflicting views\n",
      "Translate vague requirements into actionable (conflict -free),\n",
      "unambiguous specifications that can later be tested or verified\n",
      "Use case diagrams, formal requirements specifications, user stories\n",
      "Challenges: Multitude of vague with different scales and dimensions,\n",
      "conflicting requirements, concretizing requirements, verifiable \n",
      "metrics, capturing of pre -/post- conditions \n",
      "Validate the specification with customers (see problems for elicitation)\n",
      "Find appropriate forms for validation (prototypes, mockups, etc.)\n",
      "metadata: {'page': 6.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Member-only story\n",
      "\n",
      "Top 10 Architecture Characteristics / Non-Functional Requirements with Cheatsheet\n",
      "\n",
      "Love Sharma·Follow\n",
      "\n",
      "Published inDev Genius·7 min read·Jun 30, 2022\n",
      "\n",
      "ListenShare\n",
      "\n",
      "14\n",
      "\n",
      "-\n",
      "\n",
      "14\n",
      "\n",
      "Listen\n",
      "\n",
      "Share\n",
      "\n",
      "Imagine you are buying a car.\n",
      "\n",
      "What essential features do you need in it?\n",
      "\n",
      "A vehicle should deliver a person from point A to point B.\n",
      "\n",
      "But what we also check in it is Safety, Comfort, Maintainability, Ease of repair or Better mileage.\n",
      "metadata: {'source': 'https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Challenges:\n",
      "- Customers not knowing or able to describe what they want\n",
      "- Different languages, conflicting requirements, evolution\n",
      "Types and techniques:\n",
      "- Functional requirements, elicited via scenarios, walkthroughs, use cases\n",
      "- Non-functional / quality requirements, elicited via stakeholder survey\n",
      "Do never assume that you know what the customer wants!\n",
      "metadata: {'page': 4.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Requirements Specification\n",
      "Turning diverse, ambiguous requirements to concrete, actionable, unambiguous specifications that a \n",
      "software engineer can understand (and implement).\n",
      "metadata: {'page': 9.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: Examples: General Data Protection Regulation (GDPR) constraints that personal data can only be used in ways specified \n",
      "by an explicit consent.In essence: We would need to know what the ML model delivers before we developing it.\n",
      "metadata: {'page': 26.0, 'source': 'spielwiese/test_pdf/3_RequirementsEngineering.pdf'}\n",
      "\n",
      "\n",
      "\n",
      "page content: You may also look for an electric version or better speed.\n",
      "\n",
      "Why?\n",
      "\n",
      "To limit the surprises which may occur in delivering the primary function, i.e., take a person from Point A to Point B.\n",
      "\n",
      "Similarly, just like a car, motorcycle, or House, the software has its non-functional requirements called “Architectural Characteristics”.\n",
      "\n",
      "Be it a website, a mobile or a desktop app; it should have a set of quality attributes to meet end-user needs.\n",
      "metadata: {'source': 'https://medium.com/dev-genius/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheat-7ad14bbb0a9b?source=search_post---------8----------------------------'}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "for r in query_results:\n",
    "    print(f\"page content: {r.page_content}\\n\"\n",
    "          f\"metadata: {r.metadata}\\n\"\n",
    "          f\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "542bad02869b321a73a7da5260ee6f5456fa9b86f73b69a004054f84e7b0338b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
